# 百度

* 算法：红黑树，二叉树

```
```



* 数据结构：链表，数组

  ```
  链表  指针
  
  数组  
  
  
  ```

  

* tcp， ip ， 拥塞控制是怎么做到的

  ```
  三次握手 ：客户端主动发起连接建立的请求，发送syn 标志数据包，服务端接受到反馈 ack 标志包，数据位 （seq）+ 1，同时因为 tcp 中ack 和 syn 是两个标志位，所以这个确认数据包同时也可以当做 服务端的 syn 包，客户端接收到这个  ack 包知道自己的sync 包被确认了，同时确认服务端的syn 包，数据位 y+1.
  
  四次挥手：客户端主动发起连接断开请求 fin ，服务端发送确认包，进入close wait 阶段。 服务端发送断开请求 fin 包，服务端收到请求发送数据包，进入time wait 阶段，等待 2msl 时间。（主要是防止服务端没有收到ack 包，重新发送 fin 包，防止下次4元组链接建立的时候 有上次链接的数据包。1个msl 是数据包在网络上传输的最长时间，2msl 是一个来回最长需要等待的时间）
  ```

* http 302 304

  ```
  302 重定向
  
  304 未更改 (last modified)
  
  502 bad gateway 后端出错
  
  504 time out 超时了
  
  
  ```

* Https 和 http 的区别，ca 中心是什么

  ```
  https 是 http 之上多了层ssl 。
  
  他是先通过服务端下发ca证书，证书上包含了 1. 网站基本信息 + 服务器公钥  + hash 算法2. 上面信息的hash。我们通过电脑自带的 ca 公钥，通过 私钥加密 公钥加密，保证数据没有修改，拿到上述信息。然后通过 hash 算法对网站信息 + 服务器公钥 hash 是否等于给定的hash ，判断服务器公钥是否正确。 拿到服务器公钥之后就通过非对称 加密生成一个对称密钥，传递给服务端。服务端公钥加密，私钥解密防止 密钥被窃取，后面就通过这个密钥进行数据对称加密传递。
  ```

* Kafka 怎么保证消息可靠，kafka 为什么那么快

  ```
  1.发送消息的时候，设置安全等级，等待所有副本都拿到数据才回调信息。
  2.多副本机制，isr 集合中最低的position 才是partition中的水位
  3.消费者成功消费后，手动移动offset
  
  
  快：
  1.顺序读写
  2.零copy 机制
  ```

* dns 查询过程， 递归查询和迭代查询

  ```
  客户端和 本地dns 之间是递归查询。
  
  本地dns 和 多个dns 之间是迭代查询。
  ```

* ddos 攻击了解么

  ```
  流量攻击，多个ip （或者代理）对 服务器ip 或者域名发送大量请求
  
  解决办法
  
  1.提升服务器能力
  2.黑名单
  3.cdn 无效的流量起到清洗的作用，但其实带宽成本也很大
  ```

* 浏览器输入地址，中间发生了什么

  ```
  dns 解析
  1.本地hosts 文件
  2.浏览器缓存的hosts 解析
  3.本地dns hosts 解析
  4.根dns hosts解析， 一级 二级hosts 解析
  5.如果是cdn， 解析到特殊的中间服务器，判断合适的节点返回那个节点的ip，如果不是，就返回webserver 的ip。
  6.ip + host  4元组建立tcp 连接。以php 为例，请求到达 slb （负载均衡），nginx （反向代理， kong 集成了 openresty(nginx 和 lua))，phpfpm（fastcgi协议） 进程管理器(9000), php 进程中处理 （没有做微服务）。后端go 的话， kong --> consul--> 实际的pod。
  
  我的感觉就是api 网关用的是 consul 的dns 解发（consul负载均衡），grpc 微服务用的是 grpc的负载均衡 （consul 提供 ip + 端口）
  
  
  https://blog.csdn.net/chushoufengli/article/details/106741295 （slb 和 nginx 的区别）
  
  https://www.cnblogs.com/xiaxiaolu/p/14826794.html （kong + consul 实践）
  
  https://www.cnblogs.com/xiangxiaolin/p/12735289.html (consul 原理， consul 的负载均衡)
  
  https://www.cnblogs.com/FireworksEasyCool/p/12912839.html （grpc 的负载均衡）
  
  https://segmentfault.com/a/1190000018424798 （grpc 和 consul 的交互）
  
  https://tianzhipeng-git.github.io/2020/01/09/aster-1.html#%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0---consul （kong 和 grpc 的交互）
  ```

* gc 问题， stw 的时机

  ```
  内存回收主要有标记法和计数法。php 用的计数法，引用量是 0 的时候，这个变量就被回收了。
  
  go 是从root 能到达的节点先标记成 灰色，然后所有灰色节点升级成黑色，这些黑色节点能到达的节点标记成灰色，重复多次，最后剩下的白色节点回收。
  
  由于并发问题，引入了stw， 暂停所有程序的执行进行染色。为了解决这个问题，后来新生成的节点都标记灰色。新增引用关系的节点两侧都标记灰色。
  ```

* Gmp 协程调度，抢占式和非抢占式，m 和 p 的数量问题

  ```
  抢占式就是 时间片用完，强制切换到另一个goroutine，（1.14 版本引入 ？）
  
  非抢占式 （gorotine 切换时机 ？）就是除非 io 阻塞的时候进行上下文切换，否则不切换goroutine， 比如for循环空转就不切换。
  
  m 默认应该10000个，进程中可以包含的线程量。 p可以通过 runtime max 指定，一般和 cpu 个数一样 （并行的任务个数）
  
  gmp 模型，初级。global 全局队列，所有的 m 都从 g中取数据，会有严重的锁竞争问题，还有 goroutine cpu 亲和性问题。
  
  增加了p，逻辑层，每个p 绑定一个队列 （默认大小256）。p 上绑定多个m， 当堵塞的时候就切换m 去执行g。减少了锁竞争问题，也保证了cpu 亲和问题。如果本地队列消耗完了，去全局队列或者其他的本地队列里面偷取一般进行执行 （这两种优先级哪个更高）。
  ```

* 如何优雅的实现一个goroutine 池 

  ```
  目前成熟的包有ants
  
  想到的有
  1.通过channel
  
  new pool 的时候根据， pool 数量的大小， 启动一个 for 循环， 启动对应大小的 goroutin, 每个goroutine  for range 轮训 channel， 执行投递到 channel 中的任务
  
  2.通过信号量（num）
  
  new pool 的时候根据 pool 数量的大小，初始化一个类似 total 的总数，通过 atomic load, compare and swap 两步 ---》一个原子性操作 （获取数据并且判断大小），来限制同时的并发数，如果 == 0 就能再生成goroutine 了，因为 atomic 是非阻塞性操作，感觉会牺牲蛮多cpu 性能
  ```

* 内存逃逸

  ```
  可能存在的几个场景
  
  普通变量定义在栈上，函数执行结束，就被回收了，定义在堆上的变量需要通过gc来回收。一些变量原本应该定义在栈上，逃逸到堆上。通过 go tool  complie 可以来看整个过程
  
  1.函数中定义的局部变量返回出来地址 （类似野指针）
  2.变量过大，从栈上逃逸到堆上 （make([]int, 0, 100000), 这种初始化就定义很大的， append 好像不太容易开始就往堆上跑）
  3.interface 类型，编译阶段没法确定类型，很常见的就是 fmt.println 的时候
  ```

* 内存管理

  ```
  go中元素都是分配在span 上，span 有67个级别， 0级别中每块大小不确定，剩下的类似 2，4，6，8这种，每个元素的分配寻找最靠近的span。
  
  go 中寻找内存空间用的是三级缓存，
  现在 mspan上寻找 （span 组成的 page， 8kb）， 再去 mcentral 上寻找 （各个级别的span 连接撑的链表，比如67个，同时分成 空间 和非空闲），这个阶段已经是被 proccer 共享的了，所以加锁访问。再到mheap 上寻找。mheap 分成 位图 和搜索二叉树，搜索二叉树是最后一层，是内存空间和 虚拟地址的映射。
  ```

* mysql 锁

  ```
  间隙锁 （gap, 左闭右开） + 记录锁 = 
  
  唯一键 不会用到间隙锁，因为不可能有间隙。如果是区间的话 > ,如果是单调的不会加锁，非单调的就会
  ```

* mysql 事务特性，隔离级别

  ```
  隔离级别
  读未提交 （脏读，不可重复读，幻读）
  读已提交  （不可重复读，幻读）
  可重复读  （理论上会有幻读，但 innodb 通过间隙锁解决了 当前读的场景， 如果是快照读 事务开始的时候就生成快照是不会有 幻读的问题）
  串行化
  
  事务id ，生成链表。和当前执行的事务id 做对比，只能用最小于当前的事务id 数据
  
  事务特性
  
  a  原子性 undo log 
  c  一致性 代码维护
  i 隔离性 mvcc
  d  持久性 redo log 防止数据丢失
  ```

* mysql 索引

  ```
  hash 索引 （没法范围匹配）hash 表 + 链表
  b+ 树， 相比较b 树，每个node 节点存储了更多的内容，不需要存储除了 索引之外的信息。page 包含的 数据量更多。b 树的非叶子节点 和 叶子节点数据不会重复，b+ 树会，b+树的叶子节点上包含了所有的数据。
  
  explain  possbile key,  use key, key len (注意 null 会占用一个字节), sort
  
  mysql 索引，最左匹配
  
  索引建立规则：索引要建立在区分度大的列上，还有联合索引第一列就不要单独建立索引了。
  
  聚簇索引和 非聚簇索引 ，非聚簇索引 只包含索引自身和主键索引，不包含其他列值， 所以有时候select * 需要回表操作。
  
  索引建立时机
  ```

* mysql 分库分表

  ```
  分库的话主要是担心不同的业务影响，比如渠道和 订单，都放在一个 db 中，也就是一个 mysql 实例中，这个实例的cpu 内存会相互影响。而且一个db 可以用的连接数也是固定的
  
  
  分表：垂直分表 （冷热字段）和水平分表 （数据）， 常用的有时间， id， 字段hash
  
  分布式id 生成规则 ： redis id 自增， uuid, 雪花算法 （ip + 时间+ 累计count）
  ```

* Mvcc 的实现原理

  ```
  ```

* redis 的数据类型有哪些

  ```
  string， json 序列化，配置文件
  hash ，对象存储，比如设备的一些信息，uid, verison, idfa，imei，不需要每次都获取所有的字段值
  list， 消息队列，现在用的少了，缺少 ack 机制，容易丢数据
  set  好友关系，求交集
  zset  时间滑动窗口，排行榜，延迟队列
  geo 地理位置
  bitmap 点击行为
  hyperloglog  不太准确的统计行为
  ```

* redis zset 的底层

  ```
  ziplist
  
  跳跃表 + hash表，跳跃表用来进行范围查询，排序，hash 表用来存储  value 和 score 的对应关系
  ```

* redis 的内存淘汰策略

  ```
  随机删除
  最近最少使用
  最近使用频率最低
  不删除，再插入报错
  
  （以上 都可以演变成有 ttl的删除 ）
  ```

* redis 的持久化策略

  ```
  1.rdb (对所有key - value 备份)
  2.aof （对所有命令备份，压缩命令 ， 回放命令）
  
  rdb（base） + aof (增长)
  ```

* redis 分布式锁。

  ```
  redis  set， nx （not exist）, ex (ttl)
  
  lua: 获取 key 对应的value， 只删除自己的 key -value
  
  续约 ： 启动一个go 协程 ticker 定期续约
  
  redis-cluster 模式下，redlock ，超过半数的节点都加锁成功，就代表succes， 但要减去加锁消耗的时间
  ```

* redis 分布式架构

  ```
  主从
  
  哨兵（监控 + 主从）
  
  redis-cluster (去中心化，分布式扩展，也是有主从，不同节点同步信息实现了 gossip 协议，选举协议用的raft)
  
  脑裂问题
  ```

* 如果有一个排行榜，用zset， 根据积分和时间来排序，积分高的，时间最近的拍前面，

  ```
  sort -- > 积分 + （时间）， 越大的在前面
  ```

* linux 你熟悉的命令

  ```
  cd 
  ls
  lsof
  ps
  wc
  top
  cp
  mv
  tar
  vim
  tail -f
  df -h
  mem
  ```

* 流浪暴增，都打到一个upstream 上了，怎么排查

  ```
  其他的upstream 对应节点是否正常
  
  确认当前 负载均衡策略，
  
  查看是某个请求暴增 （刷的or 活动接口），还是所有请求暴增
  ```



# 米哈游

* 会出现什么状况

```
...
m := make(map[int]int, 10)
for i := 1; i<= 10; i++ {
    m[i] = i
}

for k, v := range(m) {
    go func() {
        fmt.Println("k ->", k, "v ->", v)
    }()
}

// key value 的值不一定， 用临时变量 k := k  v:= v ,改变变量作用域。 或者参数传递进去
```

* 内存泄漏

  ```
  遇到的两次内存泄漏
  
  1. errgroup 的使用，b站封装的那个。关于主协程的阻塞，并没有用 wait() 方法，而是用了 for 读取channel 堵塞。因为开始的时候设置了 errgroup 最大并发协程数，所以他底层是通过 for n 里面for range channel 实现的，wait()的时候 close了 channel， 使这个for range 在执行完之后也能不堵塞，goroutine 能被回收。如果堵塞了。这些生成的goroutine 不能正常回收，协程泄漏 ---》 内存泄漏 oom
  
  2.还是蛮经典的一个场景。 解决这个问题之后，granfa 上的内存 还是呈缓慢增长的趋势。pprof 开启，查看哪块代码出了问题。同事封装的一个 timeout 函数， select 监听了两个channel， 一个是 ctx->done() 一个是 func 执行完塞入的数据，当超时之后，消费者没了。func 塞入的channel 是同步channel， 所以执行实际func 那个 goroutine 一直得不到释放。
  ```

* channel 的底层实现

  ```
  hchan
  
  buf --> 有buf 的channel 才有，环形对垒
  
  sendx
  
  recvx,  环形队列的接受指针和 发送指针
  
  sendq  阻塞的发送goroutine 链表（双向）
  
  recvq 阻塞的接受gorouine 链表（双向）
  
  sync.Mutex
  
  close 状态
  
  优于mutex 本身的就是，如果 recvq 有等待，来数据之后，直接copy 到对应goroutine 的栈中执行，减少了一次加锁处理操作，也减少了 数据 用户态到内核态的copy。
  
  ```

  

* defer 在设么时机会修改返回值，多个defer 的顺序

  ```
  return 不是原子性的命令
  
  return 分成 赋值操作， 执行defer， return
  
  所以如果返回的结果提前定义好变量，defer 执行的时候修改这个变量，就能修改返回值了。
  
  defer 保存在栈中，先进后出的执行。
  ```

* make 和 new 的区别

  ```
  make channel map slice 的生成，底层数据结构的初始话，不修改变量类型
  
  new 返回初始化变量的地址类型，作用类似 var， := ,只是返回地址类型，比如 slice channel map 这种返回的就是nil （他们的零值不可用，所以一般不用new 生成）
  ```

  

* channel 关闭了send 会发送什么, 关闭一个已经关闭的channel 会发生什么

  ```
  pannic
  
  panic
  ```

* map 是线程安全的吗，map 的扩容规则

  ```
  非线程安全，flag 标志位，每次执行curd 的操作都会检测
  
  扩容规则，map 本质上是hash table， 他的负载因子达到 6.5 就会扩容了
  ```

* 数组和切片的区别

  ```
  切片的底层是数组，数组长度固定，切片不固定。
  数组是值类型
  切片引用类型
  ```

* Gc

  ```
  三色标记法
  ```

* GMP 模型

  ```
  goroutine 调度模型
  ```

* 进程 线程 协程 区别

  ```
  进程 程序的实体，资源分配最小单位
  线程  任务的执行， cpu分配最小单位
  协程  用户态线程，cpu 看不见，由程序进行调度，占用空间小，基础2kb 就够了，共享线程的一些成堆栈区间，有一些自己的栈和寄存器
  ```

* 微服务的注册与发现， 微服务的监控，微服务的限流，微服务怎么守护进程

  ```
  注册发现用的是consul， 代码中集成了consul 的api， 把 ip地址 + 端口号 + 服务名注册到consul 中
  
  调用方通过 服务注册名拿到 ip + 端口号，比如grpc 的client 根据自身的 负载均衡策略，把请求发送到对应的pod 上。
  
  服务监控，grafana + sls。
  sls  阿里云的 日志服务， 主要收集的是我们的业务日志。
  grafana + 普通米修斯 + metric 主要收集我们的一些业务指标日志 (metric 收集日志，普罗米修斯存储，grafana 上展示)
  
  限流用的uber 开源的那套（令牌桶，漏斗 redis，滑动窗口 redis）
  
  https://zhuanlan.zhihu.com/p/30441529 // go 中关于metic 的使用
  
  // 实现守护进程
  1. 父进程 fork 子进程，父进程退出，子进程成孤儿进程， 
  2. 子进程重新 开启会话，脱离原先会话组控制，还有一些工作目录的设置
  3. 修改文件权限。
  （supervisor 肯定也能实现）
  
  ```

* 如何批量生成几十万 或者上百万的兑换码。高并发下，一个兑换码 如何保证只能被一个人兑换一次，以及一个兑换码如何可以被多个人兑换

  ```
  1.一个兑换码只能被一个人兑换一次 （联合唯一所以）
  2.一个兑换码被多个人兑换 （每个兑换记录存一次）
  3.百万级别兑换码，xxx xxxxx , 7位数， 英文字母 26个（不算小写）， 26的五次方，百万级别。满足需求了，我启动 26 * 26 * 26个协程，每个里面 总数 /协程数 = 单个协程的生成兑换码的次数，5位，每个里面单独生成兑换码。
  ```

  

* 算法

  ```
  输入4个数字，通过加减乘除，输出一个期望值
  
  ```

  

# 作业帮

* channel 的实现

  ```
  底层是一个结构体 hchan， 返回的是这个结构体的指针，所以我们需要通过make 去生成，否则定义完成后直接塞数据，应该是 空指针的报错 nil.
  
  buf  循环队列，为了非阻塞 channel 使用的，存储数据
  
  sendx
  recvx 两个指针，对应上面的buf， 接受数据的index，发送数据的index
  
  sendq 发送数据阻塞的goroutine 双向链表 
  recvq 接受数据阻塞的goroutine 双向链表
  
  sync.Mutex  线程安全的核心
  
  通信去共享内存，而不是共享内存去通信 ，一是利用channel 可以解耦， 而是如果 sendq 有堆积，到来的数据可以直接copy 到sendq 的栈中，减少了一次加锁处理和内存copy 处理
  ```

* go 的调度原理

  ```
  gmp 模型
  ```

* select 和 epoll 的区别

  ```
  select 是遍历fd 文件，fd 所存储的数组空间有限制，只能通过遍历fd 组成的数组，去看哪个fd 有改动
  
  epoll 是通过fd 的 read ，write 事件发生，主动通知主进程，不用一直遍历
  ```

* redis 分布式锁， 羊群效应听说过么

  ```
  redis set nx, ex, 
  
  + lua 判断 锁是否是自己的
  
  + 定期续约 看门狗
  ```

* redis 缓存穿透，缓存雪崩

  ```
  缓存穿透： redis 中查询不到，直接查db。 可以对这种key 设置一个空值缓存 （口碑遇到，es 的查询太慢）
  
  缓存雪崩：做活动，redis key 同一时间大量过期，全都去查询db （可能来的时候都是散的，但是，某个点活动结束，所有key 都被删除了）， ttl 上面加上一个随机量
  ```

* 时序数据库怎么实现

  ```
  目前用到的可能就是普罗米修斯，用来存储日志的，底层怎么实现，没看，可能是用时间进行分表的
  ```

* raft 选举，高可用

  ```
  ```

* Kafka 的offset 怎么管理

  ```
  通过一个topic 去管理，当然内存中也写入了一份 （offset 是由 topic， partition， consumer group 决定）
  ```

* kafka 多个consumer group 消费同一个partition 有问题吗 ？ 同一个consumer group里 能消费同一个partition吗

  ```
  1. 可以，同一个topic 可以被多个consumer group 监听
  
  2.不能，多个 partition 可以被同一个consumer 消费，但是一个partition 不能被多个consumer 消费。（感像是没法保证offset 的移动问题）
  ```

* 数据库中的乐观悲观锁。 程序中的乐观 悲观锁

  ```
  mysql 中锁，悲观锁
  
  es 中锁， 乐观锁 （ 版本概念）
  
  
  go 中的sync.Mutex 是悲观锁
  
  atomic包 的compare and swap 应该属于乐观锁 （利用地址取值进行比较）
  ```

* 二叉搜索树，两个节点被交换了位置，怎么恢复

  ```
  ```

* 消息队列的推和拉 有什么区别

  ```
  rabbitmq redis list pub 都属于推的模式，推完了，数据删除了，
  
  kafka 是拉，通过offset 的移动，理论上可以消息的重放
  ```

* 长链接转短连接设计

  ```
  md5 后，存成记录，用来匹配。
  
  
  id  长url （唯一索引）  短url
  
  匹配的时候，端url 查询长url， 可能存在hash 冲突。
  ```

* 管段gateway 集群维护客户端长链接， gateway 分发请求到后端集群处理逻辑后，如何保证后端处理完毕回包到正确的gateway机器。 如果机器挂掉，如何最小损失情况下恢复。

  ```
  ```

* redis 高可用

  ```
  分布式集群。redis-cluster 去中心化，方便水平扩展， 通过实现gossip 协议，不同节点的更改操作都能同步。 主从模式，方便故障转移。
  
  aof + rdb 防止数据丢失。
  ```

  

# 小公司

* 设计一个高并发， 高可用的架构

  ```
  1.读多
  （读写分离，从库多配置几个， 上缓存）
  
  2.写多
  （读写分离，主库提高配置）
  
  3.负载均衡怎么做
  （轮训，权重，ip hash， url hash）
  
  4.mysql 部署，读写分离怎么做
  （网上教程配置）
  
  5.mysql 索引是什么，什么数据结构， myisam 和 innodb 区别 . 有 ab 两个索引，索引会怎么选择 ？ （a，b ）是联合索引。
  
  索引加速查找，b+ 树。 inndb 支持事务 （数据条目不保存），存储结构 数据 = 索引， 行级锁。myisam 不支持（数据条目保存），索引和数据不一样，必然回表。表锁。 ab 两个索引，判断最优索引，联合索引可能都用到。范围查询除外，当然where 顺序是可以优化的。
  
  mysql 事务， acid 怎么实现，隔离级别哪几种。 mvcc 实现，乐观锁，悲观锁
  
  
  热key 和 大key 怎么处理
  
  kafka 架构，消息的顺序消费怎么办
  
  ```

* cdn 架构，缓存的实现，用户的访问流程，怎么选择机房

  ```
  ```

* 有序数组合并

  ```
  ```

* 二叉树中序遍历 （非递归实现）

* 寻找k 值

* 岛屿数量

* K8s 的服务注册

  ```
  我们的服务注册用的是consul， 我们的微服务是基于grpc 上的go-micro 实现的，暴露到我们业务层面就是配置服务名称，实现服务定义方法的interface, 通过go-micro 注册到consul 上面，需要调用对应服务的 client 会通过服务名称去寻找对应的 ip+ port, 通过负载均衡，权限校验， 获取连接，调用对应的方法
  ```

* Rabbitmq 的消息确认机制

  ```
  消费者成功消费后给消息队列发送ack 确认，队列接收到会删除对应消息， 或者发送 nack ，这个消息会循环下次再发送。
  ```

* rabbitmq 怎么保证消息不丢失

  ```
  1.消息队列的持久化，消息的持久化都可以设定
  2.镜像队列
  3.消息的确认机制
  ```

* rabbitmq 实时性怎么实现

  ```
  启动一个消费者，一直轮训的读取消息，应该是读取不到消息就会被堵塞。
  
  然后把这个进程变成守护进程，一般可以通过supervisor。
  
  自己实现的话就是通过父进程 fork 子进程，然后删除父进程。修改子进程的会话组，文件权限组，脱离当前terminal 等的管辖。
  ```

* redis 和 mysql 一致性， 项目里面怎么用

  ```
  1.读数据，cache 没有，db 读取，写入cache 并且返回
  
  2.修改数据。修改db， 并且删除cache。（也可以先删除cache， 但是修改db 后， 还需要删除一次cache）
  
  多种模式。上面的比较基础，还有1.对外只暴露cache， 通过cache 去操作db。 操作db 又分为直接操作 和 异步写入消息队列操作。
  ```

* 高并发秒杀场景， redis 怎么设计

  ```
  1.客户端的静态数据，通过cdn 加载。获取秒杀商品的数据，通过 single flight ，帮助执行请求这段时间内打到后端的请求只有一个。
  2.秒杀时间，通过后端下发，前端自己判断， 抢购按钮置灰，然后实际抢购接口的操作，后端也做开始时间的判断。
  3.秒杀利用redis， 一个结构体 存储秒杀开始时间，秒杀商品库存，当前秒杀量，通过lua 脚本 判断秒杀量 + 1 和 秒杀库存的关系，判断秒杀是否成功，如果成功就推消息到消息队列。进行订单的异步处理。
  4.如果qps 过高。可以多生成几个redis 键，对uid 进行hash 取余，不同的uid 请求不同的redis键，每个redis 分布在不同的node 上，缓解node 的压力。
  ```

* redis 分布式架构

  ```
  1.redis 主从 （没法自动进行故障转移）
  2.redis 哨兵 （哨兵是个独立的进程，可以监控redis 实例的健康，下线有问题的redis 实例，把请求都转移到redis 从节点上）
  3. redis-cluster 去中心化分布式，通过gossip 通讯协议，去获取不同node 节点的key 情况，通过raft 协议进行主节点选举 （脑裂问题应该可以通过lead releas 去解决，通过对比两个leader 的任期，长的胜出）
  
  主节点和从节点的同步， 从节点发送bgsave 命令，主节点启动一个进程进行 rdb 数据备份，生成一个rdb 文件，一直往这个文件里面写数据。同时，把执行的命令也保存下来（aof），rdb 文件生成完之后，从节点先载入这部分数据， 再执行aof 里面的命令
  ```

* 为什么项目里面用curl 来调度服务，不用rpc， 差距在哪

  ```
  rpc 
  缺点: 维护成本高，开发效率上没有curl 快
  有点： 以grpc 为例，通过基于http2 作为通讯协议，
  1.pb 数据传输协议，可读性差，但是二进制性能更高，序列化和反序列化更快。
  2.http2 基于多路复用，相比于http1.0 的短链和 http1.1 的pipline， 真正意义上的并发，pipline 如果一个请求堵塞了，会影响后面的请求。
  3.http2 头部压缩技术，利用两边都维护一个header信息表，减少每次请求的大小。
  4.http2 有服务端推送功能。比如请求 index.js 的时候推送css 和 html，但和websocket 的实时通讯不一样
  
  除此之外，rpc 会有相应的的熔断，限流， 负载均衡机制。
  
  你们熔断是怎么做的
  基于hystrix-go 做的，配置某个时间段内错误请求占比总请求的百分比，到达某个阈值，开启百分比的走兜底请求，剩下的走整成请求，然后一直监控正常请求的占比，如果恢复了，全部走正常请求。
  
  限流用的是uber 开源的那一套 漏斗桶。
  1.我了解的有令牌桶，令牌个数使用完了，就不能用了。
  2.滑动窗口，时间戳作为score， 向前数一段时间内的请求量。
  3. uber 用的是漏斗桶。漏斗桶的核心 是匀速，uber在基础上做了优化，会把之前超过的时间累积下来，下次如果时间间隔达不到，就不用sleep， 从之前累积的时间里面减掉。
  
  负载均衡
  1.随机  (random)
  2.轮训  （foreach）
  3.加权 （类似抽奖）
  4.hash (hash 之后取余数)
  
  http:简单，容易维护。
  
  ```

  

* 协程池的设计 （简单版本）

  ```
  1.最大量 max (信号量和 for i < n 维护)
  2. 获取任务。通过把任务塞入到channel 中，读取
  3. waitgroup 等待任务执行完， close channel， 释放 goroutine
  
  这么看 channel 也挺像一个协程池，不带buf 就是 一个处理能力的池， 有buf，就是有多处理能力
  ```

* 连接池的 设计 (简单版本)

  ```
  1.最大数量，空闲数量 idle
  
  2.队列，阻塞的任务放到这个队列中，先进先出。维护顺序。
  
  3.保活。发送心跳
  
  4.均衡，先进先出。
  
  5.使用完是否要放回去，还是直接回收掉。
  ```

* slice 扩容

  ```
  len 小于 1024 的时候，容量翻倍的增长。之后25 %的增长。当然这中间的增长要满足需求。
  
  
  之前我的cashback 就是因为没有满足增长的需求， 导致数组 超长。
  
  他这个感觉是利用了 for 去增长。
  
  我的那个是在差值 diff 基础上 + 10， 不同场景的情况， 我这个一次增长，绝对不会数据越界。
  
  https://www.jianshu.com/p/54be5b08a21c // go slice 增长源码。
  ```

  



# 字节

* 打印二叉树

  ```
  
  ```



* 锁实现

  ```
  ```

* mysql 加锁分析

  ```
  
  ```

* 三数之和

  ```
  ```

* 山顶山谷问题

  ```
  ```

* 最好的卖股票时间

  ```
  ```

* 二维数组的二分查找

  ```
  ```

* bitmap 的长度多大，用到了那些hash 函数

  ```
  512 m
  ```

* 渐进式hash 的理解

  ```
  负载因子达到阈值后，会触发渐进式hash
  
  新的数据都写入到新的hash 中，老的数据往新的hash 中迁移 。每次迁移完成key， 都会把迁移的bucket index 保存，查询数据的时候，拿这个index 和 查询的 key 进行对比，判断是去新的 hash 中查询还是老的hash中查询
  ```

* kafka 的分区和消费者分配原则

  ```
  分区数 >= 消费者数
  
  ```

* 统计相同用户的访问次数

  ```
  awk 提取出用户id | sort | uniqu 求和 
  
  https://blog.csdn.net/feng973/article/details/73849586 // 这篇文章一步一步讲解各个步骤作用
  ```

* 有n 个任务，每个任务又开始和结束时间，如何安排任务的书序，完成任务的个数是最多的

  ```
  ```

  



# 马蜂窝

* es 数据超过一亿，有什么优化

  ```
  1.分页不要太大，es 查询数据是从每个分片上获取对应的数据，再merge 在一起 （比如获取前100，每个分片上都获取100个）
  2.筛选用filter， 不会按照score 排序，效率高
  3.热数据单独建索引，类似mysql 分表
  ```

* mysql 插入数据，断点重启之后，数据会丢失吗，为什么

  ```
  不一定
  
  mysql 写数据，是先写日志，在些磁盘。先写入 log buff 里面，然后 cpu 空闲或者内存不够，或者buff 满了，往磁盘上写入。我们可以设置等级，每次事务提交都写log buf， 但不是马上调用 fsync 去刷日志，而是通过每秒去刷，只要不是系统崩溃，我们的日志最后都能通过 fsync 刷成功，下次重启。（checkpoint）
  
  
  双 1 保证数据不丢失 (https://blog.csdn.net/weixin_39634067/article/details/113135429)
  
  redo log （每次事务提交都写log buff, 后面刷日志到磁盘）
  
  binlog （每次事务提交都写日志）
  
  感觉mysql 都是通过 事务来提交日志的。
  
  https://segmentfault.com/a/1190000039707144 // redolog 和 binlog 区别
  https://www.cnblogs.com/agilestyle/p/11428946.html // redolog 工作原理
  ```

* tcp 的三次握手是特有的吗, udp 会有吗

  ```
  1.tcp 面向连接，upd 不需要建立连接。所以不用三次握手
  2.tcp 可靠，udp 不可靠
  3.tcp 1对1 ，udp 多对多，可以 广播
  4.tcp 面向字节流，udp面向报文
  5.tcp 流量控制用到滑动窗口，拥塞控制用到慢开始，拥塞避免。tcp 有序通过序号，tcp 可靠通过确认机制。
  
  什么是粘包：
  tcp 面向字节流，本身是不存在包的问题。是上一层 应用层，对流数据进行切割，出现了粘包问题。
  
  1.nagle 算法会导致发送粘包问题（发送的时候 buff 满了才一起发送， 可能还会导致延迟），所以关闭了吧
  2.接收方等待buff 满了从 里面取数据，没法正确区分。
  
  怎么解决
  1.关闭 nagle 算法
  2.消息增加长度，类似conten-length （redis sds 的处理方式方式）
  3.消息增加边界， 特殊的字符（所以要crc 验证消息，防止特殊字符也是字符本身一部分）
  
  udp 会出现粘包问题吗
  
  不会，udp 面向报文，只添加元素，不拆分元素。
  
  https://segmentfault.com/a/1190000039691657 // 粘包问题讲的很好
  ```

* rabbitmq 是分布式么

  ```
  是，还有镜像模式，备份数据
  ```

* kafka 会丢数据吗

  ```
  1.生产者。有同步和异步的方式，设置成同步保证每次发送都能获取到partition和 offset，如果有问题重新发
  2.设置ack 为 （0 只发送，不关注是否收到 1 保证所有副本都能收到 -1 保证leader 和 isr 列表能收到）
  3.消费端手动提交offset
  4. kafka 批量刷盘，减少刷盘间隔。
  ```

* kafka 消息积压了怎么办，增加消费者又有么

  ```
  单个partiton 最多被一个consumer 消费，所以单单增加消费者是没有用的。
  
  可以通过增加partition 的数量。
  
  我们可以把耗时操作再查分多个消息队列，减少单个消息队列（topic）的压力
  ```

* redis 怎么平均分配数据

  ```
  通过 hash 计算key， 找到对应的槽，各个节点包含这些槽。
  ```

* redis bitmap， 为什么不用redis 命令来做交集，并集

  ```
  复杂度 o(n)
  ```

* Redis 的 分布式锁，过期怎么续约

  ```
  通过ticker, 定时生成一个协程，完成续约动作，如果动作完成，关闭ticker。
  ```

* redlock 主要解决什么

  ```
  存在主从节点，从节点和主节点存在延迟的情况。当有一半以上的节点加锁成功，就代表加锁成功。
  
  redis 和 zookeeper 分布式锁的差别。
  
  redis 主要是为了锁的吞吐量，zookeeper 主要是保证高可用。
  ```



# 得物

* lru 算法的大概实现，go怎么实现lru 算法

  ```
  最近经常使用
  
  1.map。 存储 key 节点 content， vaule 节点的 address.
  
  2. 这些节点连接成双向链表。
  
  首先map 帮我们快速定位这个 content是否存在， 如果不存在，生成节点，插入双向链表头部，返回地址，添加到map中。
  如果存在，获取节点address, 从list 当前位置中删除节点，并且把这个节点添加到list 头部。
  ```

* mysql 主从不一致怎么解决

  ```
  1.很重要的话强制读主库
  2.如果是消息队列里面，延迟几秒再执行
  
  mysql 主从同步原理
  
  binlog-->relay log
  ```

* Go 协程为什么比线程更轻量

  ```
  1.协程是用户态，线程是内核态， 协程切换发生在用户态，线程的切换需要从用户态往内核态切换
  2. 协程包含的数据更少，共享线程的一些堆栈，协程切换这部分数据不需要切换。协程切换本质上还是在一个线程上，依旧属于串行，不需要对这部分数据加锁。多线程的执行，会导致并行问题，线程不安全。
  ```

* kafka 怎么防止重复消费，kafka 的ack 和 rabbitmq 有什么区

  ```
  1.对于订单状态修改，我们可以保存一个最后一次消息修改订单状态时间，如果新的消息时间大于之前的消息时间，我们就更新，否则不更新。
  
  2.对于那种一条消息产生一条记录的，我们可以做唯一索引来限制消息的重复执行。
  
  3.并发状态的重复消息，我们通过加入分布式锁来解决。
  
  kafka 的 ack 会修改offset， rabbitmq 的ack 会删除数据。
  ```

* go 怎么实现的锁

  ```
  1.信号量的atomic 的修改。
  2.多个状态。饥饿， 唤醒，lock，wait。新生成的goroutine 和 队列goroutine 进行竞争。如果当前获取到锁的goroutine 等待时间过久，锁进入饥饿状态。新生的goroutine 不参与锁的竞争，直接去队列尾部。
  3. 为了防止runtime 调度goroutine 过于频繁，加入自旋锁，循环4次 （多个条件，多核cpu， wait groutine 为 0）
  
  
  go 怎么实现读写锁
  
  读锁，readcount 累加和减少
  
  写写 之间用互斥锁，
  
  读写之间用，写入的时候把readCount 设置很小，堵塞读操作
  ```

* Mysql 分库的场景，如何连表查询

  ```
  1.订单表，渠道表，防止在同一个实例中，共享cpu ，内存互相影响。
  
  2.数据库连接，单个实例上数据库连接数一定，如果并发都很大，容易连接量不够。
  
  代码中实现连表查询。
  
  ```

* 分布式事务

  ```
  感觉最核心的就是重试机制。看了下rocketmq 支持的分布式事务，通过发送半消息，然后一定时间之后反查这个消息的提交者事务是否执行成功。如果成功就让commit， 如果失败就rollback。然后下游保证自己的本地事务。
  
  其实感觉用一般的mq也能实现。把发送mq 这步骤拿出来，执行成功我才发送，所以消息就省去了rollback操作。然后如果消息发送失败就重试。发送成功就和rocketmq 一样，让下游自己保证自己的本地事务。
  ```

  

* 信号量和信号的区别

  ```
  https://juejin.cn/post/6906677772479889422 // go 信号量
  http://xiaorui.cc/archives/6535 // go 基于信号的抢占式调度
  ```

* php 怎么实现常驻进程

  ```
  supervisor
  
  linux 父进程fork 子进程，然后父进程结束。修改子进程的会话组，文件权限组，然他脱离 terminal 的控制，独立出来
  ```

* golang 的context 的withcancel 用过么。什么场景

  ```
  类似 withtimeout 超时的时候自动调用cancel()， 返回一个cancel() 方法，给用户自己执行。当执行这个cancel 的时候。ctx.Done() 这个channel 能返回一个消息。
  
  go 的errgroup 并发goroutine, 出现一个错误，就返回，利用的就是 sync.Once 调用cancel() 方法。
  ```

* goroutine 的变量作用域问题

  ```
  1.for 作为参数传递到闭包里面
  2.v := v 修改变量作用域
  ```

* go 怎么调度goroutine

  ```
  ```

* go 的switch 和 php 的switch 区别

  ```
  不需要break ，执行完case， 自动弹出
  
  往下执行需要添加 fallthrough
  
  switch 可以断言，获取变量类型
  ```

* kakfka 的 10个分区，一个消费者，golang 会启动几个协程

  ```
  1.如果是消费者组模式，可以启动10个协程，-- 对应
  2.如果是但消费者模式，一个协程就够了
  ```

* kafka 的offset 存在哪里

  ```
  存在一个topic 里面。
  内存里面也有一份 （topic, partition, consumer group） 三元组决定
  ```

* rabbitmq 的 ack 和 kafka 的ack 的区别

  ```
  rabbitmq 接受到ack 会删除数据
  
  kafka 接收到ack 会移动offset
  ```

* mysql 的分库分表，每个表的id 都从 1开始吗，为什么要设置

  ```
  分布式id 生成
  
  1.redis
  2.步长 （规定每个表从一个id自增）
  3.雪花算法或者uuid
  ```

* kafka 如何保证消息都发送到指定分区

  ```
  1.单partition
  2.设置 message 的key， 会根据key 进行hash，发送到对应分区
  ```

* 整体业务架构大概聊一下，服务之间通信方式，信息流处理

  ```
  聊一下域名的解析过程。
  
  服务之间通信用的grpc
  
  关于信息流的去重，我是这样想的：我们的商品信息流，用户翻页深度最多也就20， 20 * 20 = 400个商品，我们只需要下次推荐的商品不在这400个内部，就可以了。hash + 队列， hash 用来去重，队列用来数据的增加和减少。
  ```

* 服务的限流是怎么做的，服务熔断是怎么做的

  ```
  限流： 1.令牌桶
  2.漏斗桶
  3.滑动窗口
  
  熔断--》定期获取某个接口异常数据占总请求量，计算占比，和阈值比较。达到某个阈值，进行分流。
  ```

  



# 小米

* mysql 的undo 原理，中继日志干嘛的

  ````
  relay log 用来slave 节点同步数据的。
  
  undo 日志用于数据的回滚，判断当前record 能否被别的事务读取到。通过事务id 找寻那个节点的undo log 日志。
  ````

* 二叉树的非递归前序遍历

  ```
  ```

* Nginx 和 php 的关系，一个请求进来怎么到php的

  ```
  nginx 需要安装 php-fpm 模块，nginx 把请求转发给 php-fpm 9000端口，php-fpm 是 php进程管理器，和 nginx 之间通信用的fastcgi协议，他的master进程接受请求，让worker 进程处理请求，worker进程中有php 解释器，对请求进行处理。
  ```

  

# 度小满

* 有序数组里面查询某个值的出现次数

  ````
  二分查找到这个值。o (logn)
  
  再像两边遍历
  ````

* mysql 的mvcc 实现原理

  ```
  mvcc 是在 rr 和 rc 下面。
  
  每条记录的变更，都会写一条undo log，undo log 连接成一条链表， 这些undo log 上面有当前执行的事务id。
  
  我们通过 select 执行的时候生成的read view (快照)，对比记录的事务id 和 read view 的活跃id ，最大事务id 和 最小事务id .判断当前记录能否被 观察到，如果不能按照链表 回溯到上一个可以被读取的节点。
  ```

* redis 的rehash 过程，中间有读写会怎么处理？断电呢

  ```
  生成一个新的hash， 顺序迁移 key， 迁移的key 在结构体中存储，下次查询key 的时候，和当前key 做对比，判断key 是去新的hash 中查找，还是在老的hash 中查找。
  ```



# b站

* go的引用类型

  ```
  slice, map, channel, interface, function
  
  值类型
  int string arr bool float
  ```

* go 的select default 作用

  ```
  让 select 不堵塞
  ```

* go 的defer 执行顺序

  ```
  栈，后进先出
  
  和return 相比
  
  1. 先赋值给结果集
  2.执行defer
  3. return 结束函数
  ```

* 两个goroutine，怎么控制先后顺序

  ```
  main c1
  
  g1  <-c1, c2 <-
  
  g2  <-c2
  
  ```

* Channel 被关闭还能读取吗，多次读取会返回什么

  ```
  先把channel 中数据读取光，这时候是感觉不出来是否关闭的。
  
  读取完了之后
  
  for range 形式肯定就不能
  
  select 形式还可以，读取两个值，第一个是该类型零值。第二个是false。 select 在这种模式下还是非阻塞的，之前没关闭，会阻塞到有值才能执行。
  ```

* go 的缓冲channel 和 单个channel 区别

  ```
  缓冲channel ，有个buf 循环队列可以存数据，
  同时 有send 和 recv 指针，代表数据发送和接受的index
  
  
  单个channel 是堵塞channel。同步channel。必须得有对应接受者
  ```

* go 的并发模型

  ```
  csp 并发模型。 1.channel 去控制并发。 2.waitgroup 控制并发。 3. ctx 控制并发
  
  gmp 调度模型。
  ```

* golang withgroup实现

  ```
  对计数信号量的控制，用的atomic 包。
  
  add 增加count
  done 减少count
  wait，阻塞 count != 0
  ```

* 什么情况下用rabbitmq， 什么情况下用kafka

  ```
  1.延迟队列
  2.内存rabbitmq， 剩下kafka
  3.消息回放kafka， 剩下rabbitmq
  ```

* 订单表的分库，如何查询。数据量比较大的话

  ```
  买家 （分表键）
  
  卖家  （分表键），通过监听 binlog ，实现插入。
  
  也可以在上面价格es 查询。
  ```

* 304 原因和场景

  ```
  not modified, 一些css html 文件没有修改，走的本地缓存。请求的资源商会携带 since modified 的时间，如果 这段时间内没有修改， 就不用返回资源
  ```

* redis bitmap 特点

  ```
  底层string
  只能增加不能介绍
  count 复杂度 o(n)
  ```

* Go 的读写锁

  ```
  read read 之前通过计数型信号量，可以多次叠加，lock 增加， unlock 减少, 所以不堵塞
  
  write write 之间通过互斥锁，也是信号量，堵塞
  
  read write 之间通过修改信号量。 write 的时候，信号量改成巨小的值，所以会堵塞read. read 的时候 信号量有值，不能 write
  ```

* 外部请求很慢，该怎么排查，服务器资源不足怎么办

  ```
  1.查看cpu 查看负载，查看内存 (可能别的服务相互影响，可能协程泄漏)
  2.查看jager 日志。多少次sql redis 操作
  3.查看慢sql
  4.查看qps， 查看jaeger （实现了opentracing 规范，集成了jaeger）
  ```

  



# 快手

* cdn工作原理

  ```
  给域名配置cname 记录，cname 会被dns 解析到特定的中央服务器。 后面用户向中央服务器发送请求，中央服务器会根绝周边节点的健康状况，负载，分配合适的节点供用户访问。
  ```

* go 的 init 用过吗

  ```
  引入包，对包的初始化工作。
  
  我们在链接db 的时候，就需要先导入mysql 的driver 包，但我们不需要使用这个包里面的具体方法，单只想调用init 方法能自动执行，所以一般
  
  import _  xxxx
  
  顺序 ： const, var , init, main
  
  ```

* 快速排序

  ```
  以一个数为base
  
  从右-》左，找到第一个小的数 （high -> low ,调换位置，两个high）
  
  从左-》右，找到第一个大的数 （low -> high 调换位置，两个low）
  
  调换位置，最后 数字和low 调换位置， 返回low
  
  递归执行。
  
  复杂度 o(nlogn), 最差复杂度 o(n2)
  ```

* go 的map 怎么删除数据

  ```
  delete
  ```

* go 的 sync.map 

  ````
  map 非线程安全，并发的时候，对 map 做修改， 有个flag 位置会判断当前map 是否在被修改，会panic。
  
  出现了sync.map
  
  相较于 sync.mutex + map, 主要是读写分离，先走读map， 如果有数据，而且没有脏标志。直接不加锁读取数据。
  
  如果有脏数据，会穿透到dirty map 中读取。同时有个count 计数，如果 count missing 的 次数 == len 的时
  
  候， 就会触发 dirty map 去 覆盖 read map。
  
  ````



# 边锋

* redis 的连接和mysql 的连接有什么区别

  ```
  redis 的 网络io 用的是 多路复用， mysql 线程池的模式 （处理完一个请求，线程放回线程池中）
  
  redis 的瓶颈不在 cpu， 内存处理，所以瓶颈在 网络io， 使用了效率更高的多路复用
  
  mysql 瓶颈不在 网络io， 所以使用了通用性更高的线程池。
  ```

* rabbitmq 积压会导致内存爆掉，kafka 为什么不会

  ```
  rabbitmq 内存型，不管持久化还是非持久化，数据都会塞入到内存中
  
  kafka 数据使用日志形式保存，buff 内的数据会定时刷新到磁盘上顺序写入。
  ```



# 货拉拉

* 502 504

  ```
  502 一般是php-fpm 报的
  504 一般是nginx 超时报的
  ```

* mysql 死锁的产生，如何防止

  ```
  1.对于不同的记录，按照相同的记录访问顺序
  2.长事务尽量缩短
  3.设置锁超时等待时间 innodb_lock_wait_timeout
  ```



# 滴滴

* go的协程比线程轻量在哪

  ```
  1.协程靠程序调度，协程间切换发生在用户态。线程是cpu 调度的最小单位，比cpu 可见，线程切换发生在内核态。需要用户态往内核态切换
  
  2.协程 （base 2kb）共享线程的一些堆 栈空间，这批数据在线程切换的时候不需要变换。协程切换本质上还是在单个线程上切换，没有并发问题，属于线程 (1m)安全。线程间切换，会有并发问题，线程不安全。
  ```

* 堆排序

  ```
  大顶堆的特点：每个结点的值都大于或等于其左右孩子结点的值，我们把大顶堆构建 完毕后根节点的值一定是最大的，然后把根节点和最后一个元素（也可以说最后一个节点）交换位置，那么末尾元素此时就是最大元素了
  ```

* go 的 runtime

  ```
  ```

  
