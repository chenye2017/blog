* go 中字符串不可以改变， redis 中字符串可以改变。（和并发没有关系，主要是内存copy）

```
怎么修改string. go 中字符串的修改依赖的是 string ---> []byte, 然后修改这个 slice 中内容，slice 可以修改，所以线程不安全。 string[0] = "" 这样是不能修改的，保证了线程安全，我们修改的时候不用加锁。

s := "foobar阿斯蒂芬"
fmt.Println(s)
fmt.Println(&s)
s = "qweqweqweqweqwe"
fmt.Println(s)
fmt.Println(&s)

内存地址不会改变， 因为值就是这个变量的地址。（感觉这个经常变就有问题了，毕竟是变量地址）

string 本身还是结构体，结构体中包含一个指向 slice的地址，这个slice 我们并不会修改，我们修改的时候就是新建了一个slice， 然后改变了这个结构体中对于slice 的指向。所以说string 是不可以改变的。

只读防止了copy on write （https://zhuanlan.zhihu.com/p/366707663)。
```



* Redis 数据结构

string ： sds，二进制安全，判断len 用特定字段， 而不是和c 那样遍历，复杂度 o(1). 类似 go 的 slice ，可以动态改变，也有扩容机制,（可以预分配空间）但没有缩容机制，用free 空间去存储增加的数据 (包含 len， free， buf)。像go java中string 本身是不能修改的，只读（防止copy on write ）

list : list 需要的就是可以头尾插入，所以其实数组也能满足条件。 数据量比较多的是双向链表， linkedlist，有头尾指针，常用操作复杂度都是o(1))。数据量比较少的时候 出现了 ziplist。通过偏移量直接计算位置。 现在逐渐被quicklist 取代。  节点是  ziplist ，节点之间 组成link list

Dict: hash表（数组） + 链表，hash 冲突的时候，就追加在链表上. 渐进式hash （rehash 的时候会阻塞，所以会生成两个hash， 读取的时候从两个hash 上都进行读取）。

set ： hashset， 特殊的map， value 是 nil

zset ：1. set 的插入需要保证顺序，所以可能是随机插入，所以不能用数组，只能用链表。

			2. 因为要范围查找，所以要提高索引效率，跳跃表。
			3. hash 主要用来 o(1)的查询



* 跳跃表

  ```
  https://zhuanlan.zhihu.com/p/23370124
  ```

* 为什么用跳跃表不用平衡树

  ```
  不和b+树比较是，b+树是工程树，在平衡树的基础上演变出来的
  
  不用hash 表，是因为不方便范围查询
  
  1.相比较平衡树 （比如红黑树）， 更矮， 时间复杂度 lognM, 加入结点，只需要修改指针就好了，不需要重新平衡，或者标记
  2.指针更少。平衡树 2n 个指针， 跳跃表 1/(1-p) 个指针
  
  ```



* 网络模型

  ```
  https://zhuanlan.zhihu.com/p/54580385
  
  1.阻塞io
  2.非阻塞io （不阻塞，一直询问）
  3.多路复用 （主要一个线程可以监听多个fd， 非阻塞，事件通知）
  4.信号驱动io
  5.异步io （真正意义上的非阻塞）
  ```

* redis 6.0x 多线程为什么应用不广泛

  ```
  多线程主要是解析命令和 拼凑结果到response 中
  
  相比较单线程，这块的提升，可能代价比较大，相较于 多核机器上部署多个redis 实例，和 多核机器上部署单个redis 实例，又或者是 单个redis 实例因为是多线程，需要上下文切换，不划算。
  ```

* redis 怎么接受处理命令的

  ```
  1.redis 网络模型，非阻塞io 多路复用，多个fd 存在于netpool 中，当fd 有read write 事件的时候会主动通知主线程去处理请求。请求会被写到队列中，被redis 的命令处理器处理，命令处理器分发命令，比如建立连接的请求和 查询修改的请求。
  2.redis 的多线程主要在于解析命令和 拼凑结果到返回response 上。
  ```

* 过期键的删除策略

  1.惰性删除。使用key时才进行检查，如果已经过期，则删除。缺点：过期的key如果没有被访问到，一直无法删除，一直占用内存，造成空间浪费。（我们自己实现的本地缓存一般这样删除，当下一次访问的时候如果存在，就开启一个协程去删除）

  2.定期删除。每隔一段时间做一次检查，删除过期的key，每次只是随机取一些key去检查。（redis ，过期的键放在一个集合中）

  3.定时删除。为每个key设置过期时间，同时创建一个定时器。一旦到期，立即执行删除。缺点：如果过期键比较多时，占用CPU较多，对服务的性能有很大影响。
  
* redis 数据满的时候怎么删除键

  ```
  1.lru 最近最少使用
  2.lfu 最近使用频率最低
  3.不删除，直接报错，不给插入
  
  上面又会有个策略，在ttl 中删除。
  ```

  



* list hash，set， zset 都是容器。这些容器在元素为空的时候会被自动回收

除了 string ，的set 能带有过期时间，剩下的操作都要单独 expire 设置时间。(原因不详)



* Redis 突然挂了怎么办

  1、从系统可用性角度思考，Redis Cluster引入主备机制，当主节点挂了后，自动切换到备用节点，继续提供服务。

  2、Client端引入本地缓存，通过开关切换，避免Redis突然挂掉，高并发流量把数据库打挂。（第二种基本不考虑）



* Redis 分布式锁

1. 核心 setnx 和 expire 指令的统一，出现了 set 指令添加参数。即使这样也可能在expire 阶段出现死锁， 核心就是 expire 时间足够短。 （set 指令）
2. 如果expire 太短，执行任务过久，锁失效了怎么办。可以启动一个goroutine 主动去续约锁 （看门狗的作用）（续约）。
3. 为了防止别人删除你的锁。可以通过 ip+ goroutineid 来设置值，删除前先通过lua 脚本获取值 ，是否相等，相等再删除。（get delete）
4. 可重入锁 (如果当前进程获取到，后面的操作依然可以获取到，而不会被锁住)，不推荐，但是实现原理一般就是 本地变量用map 存入锁的个数，如果已存在key ， key count ++ 。感觉就是类似go的read lock



* Redis hyperloglog （额外的结构）

工作中的使用 :

之前在做商品口碑数据的爬取的时候，我们消费者每天从kafka 中消费商品链接，产品希望知道每天爬取的商品数有多少，来评估口碑对商品的影响程度是否足够，之前是我们每次更新商品链接的时候会对这条记录修改抓取时间，后来商品方觉得这个字段没有必要，不允许更新，我们没法通过 更新时间去统计，而且通过更新时间去count 也比较慢，所以使用了redis 的 hyperloglog。

两个指令 （pfadd, pfcount, pfmerge 对于cluster 的使用不支持）（cluster 对于 mget， pipline 等这些多key 操作都 不是很好）。

原理就是通过  hash 之后的随机数，尾部出现1 的最大位置估算 存入了多少数据。分桶只要是为了平均误差。

(去重就想到了 set， set 想到了hash)

(上述场景，有bitmap ，hashmap 都可以 做到，但是hyperloglog 在大批量数据的时候内存固定 12k)



* Redis 布隆过滤器

工作中的使用：

外部商城在公司app上投放广告。产品的需求是今天某用户点击，这个广告后面依旧展示( 红包)， 但是变灰了。如果每个用户记录条数据，数据太多，没必要。可以对用户行为设置成bitmap， 展示前先查询下（hash key 是用户id），如果 true， 展示灰色， 否则展示原色。（这个bitmap 不属于布隆过滤器）

原理： 多次hash， 没有一个重复值，就是不存在。

可能出现hash 冲突，导致误判



* Redis  简单限流

zset  ， score 是时间戳， zrange 获取 set 内容。 延迟队列也可以使用 zset 去实现， 同样score 是时间戳 ， 这个时间戳不是当前时间，而是当前时间 + 延迟时间。



* Redis Geo

底层 zset ，但是容易出现大key。



* Redis scan 

利用游标遍历数据。

```
复杂度虽然也是 O(n)，但是它是通过游标分步进行的，不会阻塞线程;
提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是一个 hint，返回的结果可多可少;
同 keys 一样，它也提供模式匹配功能;
服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数;
返回的结果可能会有重复，需要客户端去重复，这点非常重要;
遍历的过程中如果有数据修改，改动后的数据能不能遍历到是不确定的;（应该是因为 这个key 所存在的位置不一定）(es 遍历数据也用的scan， 但es 一般好像不用 scan， 就重新建立了)
单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零 （应该是从头开始）

scan 本质上是对 redis 这整个 hash + list 遍历， 因为 hash 表上的 node 是无序的，所以可能新增的数据遍历不到
```



* 大value 的坏处

  ```
  1.扩容的时候申请更大的内存空间。
  
  2.大value 的读取可能会阻塞后面指令。
  
  3.redis 操作很快，对于大vlaue 的频繁读取，很消耗网络带宽
  
  4. Value过大会导致某个节点 key 数量偏少，造成数据偏移，负载不均衡。
  ```

  

* Redis 设计一个秒杀系统

```
https://tech.antfin.com/docs/2/63920

1. 准备阶段， 大量的请求。静态资源 cdn 缓存，浏览器缓存。 动态资源， 因为数据一致， 用缓存，用single flight。
2. 秒杀阶段。 利用lua 脚本执行的 原子性。 先定义一个 struct， 分别有 1.秒杀是否开始 （可以给客户端一个时间，让客户端自己先判断，如果有请求来我们这边，我们也加上一个判断。 客户端点击后到有返回，都是灰色，不能再点，服务端也加一个分布式锁）。 2.秒杀总量。 3.当前秒杀量。 当前秒杀 + 1 <= 库存，就可以下单
3. 后续阶段。 成功后把抢到秒杀的人放入消息队列中，异步处理数据。
4. 比如 rds 只能抗住10w qps， 我们 100w qps， 可以通过分片去降低压力。

```



* redis key 过长导致的危害

```
Dict字典结构中，存储数据的主题为DictHt，即哈希表。而哈希表本质上是一个DictEntry（哈希表节点）的数组，并且使用链表法解决哈希冲突问题（关于哈希冲突的解决方法可以参考大佬的文章 解决哈希冲突的常用方法分析）。

所以在这里实际存储时，key和value都是存储在DictEntry中的。所以基本上来说，大key和大value带来的内存不均和网络IO压力都是一致的，只是key相较于value还多一个做hashcode和比较的过程（链表中进行遍历比较key），会有更多的内存相关开销。

结论：
大key和大value的危害是一致的：内存不均、阻塞请求、阻塞网络。
key由于比value需要做更多的操作如hashcode、链表中比较等操作，所以会比value更多一些内存相关开销。
```



* Redis 大key 解决方案

```
1.单个简单key的存储的value过大的解决方案：

（类似我们金刚位）将大key拆分成对个key-value，使用multiGet方法获得值 (注意这快要是 multi get， 事务的话会阻塞 redis 的执行效率， 但又要注意 现在的分布式 redis， multiget 获得的key 可能在不同的集群上，所以网络io 肯能要多次网络io)，这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的IO操作。

2. string， hash、set、zset、list中存储过多的元素的解决方案：

1).类似于第一种场景，使用第一种方案拆分; （比如hash， 根据 field， 先hash， 再去对应的key 中查询）

2) string， 转hash。每次只获取部分数据。
```

* redis 热key 处理

  ```
  1.单个key 生成多个 key， 分布不同节点上
  2.本地缓存
  3.single flight 降低服务器压力
  ```

* redis 集群方案

  1.主从 （手动切换），没办法水平扩容

  2.哨兵模式。只是引入了哨兵机制，依旧没办法水平扩容

  3.cluster 模式，去中心化。保证高可用，副本 （节点间的数据同步并没有用到zookeeper， 而是使用redis 自己的协议，发送心跳包）

* Redis 集群同步数据

```
1、slave启动后，向master发送sync命令
2、master收到sync之后，执行bgsave保存快照，生成RDB全量文件
3、master把写命令记录到缓存
4、bgsave执行完毕之后，发送RDB文件到slave，slave执行
5、master发送缓冲区的写命令给slave，slave接收命令并执行，完成复制初始化。
6、此后，master每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性
```

https://mp.weixin.qq.com/s/RRVCJS_X60ugA_52h38TBA

* redis 怎么做扩容

  ```
  为了避免数据迁移失效，通常使用一致性哈希实现动态扩容缩容，有效减少需要迁移的Key数量。
  
  但是Cluster 模式，采用固定Slot槽位方式（16384个），对每个key计算CRC16值，然后对16384取模，然后根据slot值找到目标机器，扩容时，我们只需要迁移一部分的slot到新节点即可
  ```

* 为啥是16384 slot

  ```
  太多了，心跳包太大
  ```

* redis 集群原理

  ```
  一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，组成一个集群。
  
  数据存储通过分片的形式，整个集群分成了16384个slot，每个节点负责一部分槽位。整个槽位的信息会同步到所有节点中。
  
  key与slot的映射关系：
  
  健值对 key，进行 CRC16 计算，计算出一个 16 bit 的值
  将 16 bit 的值对 16384 取模，得到 0 ～ 16383 的数表示 key 对应的哈希槽
  ```

  

* redis 持久化原理和优化

  ```
  aof:记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。(指令) （接受每秒的数据丢书）（指令瘦身）
  
  执行频率：
  1.每秒执行
  2.每条命令执行
  3.xxx
  
  
  rdb:在指定的时间间隔能对你的数据进行快照存储。（数据库内容）
  
  执行评率：
  多少次写入操作执行。
  
  1.save （阻塞）
  2. 调用bgsave （redis 自身的时间ticker）
  
  一般数据恢复，靠rdb 打底， aof 恢复近期数据
  ```

* redis 内存淘汰机制

  1.lru 最近最少使用

  2.lfu最近最少频率使用

  3.fifo

  4.随机
  
  （上述三种方案可以扩充到再设置的ttl 范围内）



* redis 的哪些特性

  ```
  1.性能高， 读的速度是100000次/s，写的速度是80000次/s
  2. 数据持久化，支持RDB 、AOF
  3. 支持事务。通过MULTI和EXEC指令包起来。(期间会阻塞别的指令)
  4.多种数据结构类型
  5.主从复制
  6. 其他特性：发布/订阅、通知、key过期等
  ```



* redis 为什么这么快

  ```
  https://cloud.tencent.com/developer/article/1745894
  
  1.完全基于内存，没有磁盘IO上的开销，异步持久化除外。
  2. 单线程，避免多个线程切换的性能损耗，也避免了多线程可能产生的竞争问题，底层数据也不用加锁 。redis 速度的核心是网络io 和 内存大小。
  3. IO多路复用机制 和 非阻塞 io。（poll）
  4. 底层的数据存储结构优化，使用原生的数据结构提升性能。比如 string 底层是 sds， 对于len 方法o(1)的复杂度。 队列 是双向链表，而且还有头尾指针，对于两边操作很快，数据量小的时候用数组实现压缩列表，通过偏移量计算很快。
  ```

* Redis 网络 io 模型

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/ofen8xlxqk的副本.png)

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/pra9wx9r05的副本.png)

  ```
  https://cloud.tencent.com/developer/article/1790992
  
  6.x 之前是 单线程 reactor 模型。 
  
  之后是 多线程模型
  
  4.x
  
  socket -> i/o multi 多路复用 -》 解析客户端参数->处理任务-> 回写数据
  
  6.x
  
  socket--> i/o 多路复用 --> 多线程解析客户端参数 --》写入队列--》处理任务--》多线程回写数据给客户端
  
  ```

* redis 的 rehash 过程，如果断电会怎么样

  ```
   ht[0]，是存放数据的table
   ht[1]，只有正在进行扩容时才会使用，它也是存放数据的table，长度为ht[0]的两倍
   进行读操作：比较当前key的大小和 rehashidx的大小，来选择
   进行写操作：直接写在ht[1]中。
   rehashidx 初始是-1，开始rehash则为0，每次rehash都+1，
   rehash结束则修改为-1
  ```

  

* redis cluster 结构

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20210920000352.png)

  ```
  
  ```

  

* redis 雪崩，穿透，击穿

  ```
  雪崩， 随机值给上
  穿透，没有获取到的给一个空值 （这个口碑之前很容易出现，优化后就好了）
  击穿，single flight ，单飞。
  ```

  

* redis 做队列，如果消费者挂掉了，这个数据丢失了怎么办

  ```
  不管是 list 还是 pub sub 这种模式， 都会丢数据
  
  list 没有确认机制， pub sub 只是转换数据，并没有实际的空间存储数据， 所以不要用
  
  最新的stream 应该可以满足数据丢失，但一般都用kafka ，rabbit， rocket
  ```

* bitmap 多大

  ```
  bitmap 底层是 string， string  512 m，  9 + 10 + 10 + 3  =32， 2 的32 次方
  ```

* bitmap 缺点

  ```
  统计时候的时间复杂度 o(n)
  ```

* 为什么用跳跃表不用红黑树

  ```
  1.红黑树 二叉树，太高
  2.红黑树不容易做范围查询(不容易，但也可以)，跳跃表最下面一层是双向链表 
  3.红黑树重新标记麻烦，跳跃表最多只是相邻节点的变动
  ```

* zset 结构

  ```
  数量较小的时候 ziplist ，压缩链表
  
  较多， hash+ 跳跃表， hash 帮助快速查找元素和去重
  
  跳跃表帮助排序和范围查询
  ```

  

* select poll epoll 的区别

  ```
  fd 文件集合 读，写 ，异常fd
  
  select， 遍历 fd 集合，时间复杂度 o(n), 上限1024
  poll 改了存储结构， 依旧轮训，复杂度 o(n), 上限 1024
  epoll 事件轮训机制，可以监听到具体某个 fd 改变。
  ```

  

  

  

  
