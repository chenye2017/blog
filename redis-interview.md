* redis 哪些场景在使用

  ```
  分数据结构来说吧。
  
  1.string (一些kv 配置，还有分布式锁)
  
  2.hash (用户关系，用户结构)
  
  3.list (少，消息队列)
  
  4.set (去重，最近购买用户uid)
  
  5.zset (排行榜)
  ```

  

* 

* 

* redis 和 memcached 区别

  ```
  不同点：
  1.redis 支持更丰富的数据类型， string， hash， set， zset， list， 而memcached 只支持 key-value
  2.redis 支持数据的可持久化， 重启后可以再次加载使用。memcached 重启或者挂掉后，数据就没有了。
  3.redis 支持发布订阅，lua脚本，事务等， memcached 不行
  4.redis 原生支持集群模式，memcached 不行。依靠客户端往集群中分片写入数据
  
  相同点：
  1.都是内存型
  2.都有过期策略 
  ```

* mysql 和 redis 一致性的保证

  ```
  常用的方法有下面：
  
  先更新数据库，再更新缓存。 
  （感觉更靠谱，写入数据是准确的，只是要考虑并发的问题，也可以引入延迟重置）
   (更新缓存失败，协程重试多次）
  并发问题。分布式锁
  
  先更新缓存，再更新数据库。 （不推荐）
  数据库更新失败，可以回滚，缓存的话此时已经写入了，无法保证回滚成功，要引入新的操作，新的操作还可能失败。
  
  先更新数据库，再删除缓存。 （需要考虑主从延迟，双删）
  读的时候可能存在主从延迟，需要双删。
  
  先删除缓存，再更新数据库。（不推荐）
  并发量大的话，容易还是读到脏数据，不推荐。
  
  
  最后要保证的点：
  延迟删除，保证最后的准确性。感觉缓存的意义是，可能不一致，但这个时间不能太长，不能因为等到缓存过期，这个脏数据才被删除。
  
  
  工作中千万不要把 缓存放到事务中，很难维护。
  ```

  

  

* go 中字符串不可以改变， redis 中字符串可以改变。（和并发没有关系，主要是内存copy）

```
怎么修改string. go 中字符串的修改依赖的是 
string ---> []byte, 然后修改这个 slice 中内容，slice 可以修改，所以线程不安全。 
string[0] = "" 这样是不能修改的，保证了线程安全，我们修改的时候不用加锁。

字符串不能修改的好处：
1.如天生线程安全，大家使用的都是只读对象，无须加锁；
2.再者，方便内存共享，而不必使用写时复制（Copy On Write）等技术；
3.字符串 hash 值也只需要制作一份。


s := "foobar阿斯蒂芬"
fmt.Println(s)
fmt.Println(&s)
s = "qweqweqweqweqwe"
fmt.Println(s)
fmt.Println(&s)

内存地址不会改变， 因为值就是这个变量的地址。字符串是值类型

string 本身还是结构体，结构体中包含一个指向 slice的地址，这个slice 我们并不会修改，我们修改的时候就是新建了一个slice， 然后改变了这个结构体中对于slice 的指向。所以说string 是不可以改变的。

只读防止了copy on write （https://zhuanlan.zhihu.com/p/366707663)。


redis 单线程处理，不需要考虑线程安全
```



* Redis 数据结构实现以及应用场景

  ```
  string 
  场景：
  1.小对象序列化后的存储
  2.计数
  3.分布式锁： 
  sds （简单动态字符串）
  
  1.二进制安全, 因为结尾的判断不再通过 空字符，而是通过长度 len 。判断len 用特定字段，所以不担心二进制文件字符冲突。
  2.通过单独字段保留字符长度，所以时间复杂度 o(1). c语言是遍历，时间复杂度 o(n)
  3.可以动态改变大小，也有扩容机制， api安全，c 语言操作 string 的api 不安全，不能自动扩容容易溢出。redis string（可以预分配空间）但没有缩容机制，用free 空间去存储增加的数据 (包含 len， free， buf)。
  
  题外话：
  像go java中string 本身是不能修改的，只读, 线程安全， 防止copy on write。 redis string 可以动态改变
  
  
  
  list: 
  场景：
  消息队列 （没有ack 机制，不能用消费者组的形式）
  
  底层：
  quicklist。
  
  
  
  hash 
  场景：
  1.对象场景，比如用户个体，只想获取性别或者年龄这种。
  
  （listpack 和 hash 表）:
  
  hash 表（数组） + 链表，hash 冲突的时候，就追加在链表上. 
  渐进式hash （ 一次性hash 会堵塞 。元素有两个hash 表，rehash 的时候 读取的时候从两个hash 上都进行读取）。
  
  
  set :
  场景：
  1.需要去重的集合，比如用户关注列表
  （整数集合 和 哈希表）
  
  
  zset: 
  场景：
  1.排行榜
  2.延迟队列
  （listpack 和 hash表）
  
  
  hyperloglog (大小固定)
  海量数据统计，统计 uv， 但有误差
  
  
  bitmap （最好分片使用，不能造成大key）
  string 的底层， 二进制。可以用进行用户签到统计
  
  geo
  地理位置
  
  stream 消息队列。
  
  ```

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230213091351.png)

  

* redis 是单线程吗

  ```
  说redis 单线程主要是（执行指令） 接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端
  
  redis 程序不是单线程的
  
  1.关闭文件
  2.aof 内容刷到磁盘。重写aof 文件，rdb 文件保存。
  3. 释放内存 （unlink key）。删除大key 别用del 命令了，会堵塞。用unlink 异步删除。 （因为删除key 不单单是删除掉内存中内容，还会修改内存布局）
  
  
  ```

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230204113757.png)

redis 单线程模型

![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230204114408.png)



* redis 单线程为什么还这么快

  ```
  1.Redis 的大部分操作都在内存中完成，并且采用了高效的数据结构，因此 Redis 瓶颈可能是机器的内存或者网络带宽，而并非 CPU，既然 CPU 不是瓶颈，那么自然就采用单线程的解决方案了；(大 key 会导致高流出)
  
  2.Redis 采用单线程模型可以避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
  
  3.Redis 采用了 I/O 多路复用机制处理大量的客户端 Socket 请求，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。
  ```

* redis6 之前为什么用单线程， 之后为什么用多线程

  ```
  CPU 并不是制约 Redis 性能表现的瓶颈所在，更多情况下是受到内存大小和网络I/O的限制，所以 Redis 核心网络模型使用单线程并没有什么问题，如果你想要使用服务的多核CPU，可以在一台服务器上启动多个节点或者采用分片集群的方式。
  
  
  是在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。
  
  所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。但是对于命令的执行，Redis 仍然使用单线程来处理，所以大家不要误解 Redis 有多线程同时执行命令。
  
  Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。
  ```

* redis 如何实现数据不丢失

  ```
  1.AOF 日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里；
  2.RDB 快照：将某一时刻的内存数据，以二进制的方式写入磁盘；
  3.混合持久化方式：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；
  ```

* redis 在什么情况下可能丢失数据

  ```
  1.aof 记录。 先写指令，再写aof， 如果中间断电了，会丢掉当前指令。
  
  2. aof 回写磁盘。
  
  ```

* aof 回写磁盘策略有哪些

  ```
  always. 同步写磁盘
  no。 不主动回写磁盘，通过内核协调
  every sec. 每秒回写磁盘
  ```

* aof 备份或者重写过程中，aof 文件内容一定是最新的



* rdb 备份数据过程感觉和 aof 有点类似，都是 fork 子进程。父进程和子进程共享数据，copy on write 

  ```
  rdb 触发时机
  
  save 900 1
  save 300 10
  save 60 10000
  
  
  900 秒之内，对数据库进行了至少 1 次修改；
  300 秒之内，对数据库进行了至少 10 次修改；
  60 秒之内，对数据库进行了至少 10000 次修改。
  ```

* 一致性hash （todo）

  ```
  ```

* redis 脑裂问题怎么解决

  ```
  min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
  min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。
  ```

* redis 主从模式中，过期键如何处理

  ```
  当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。
  
  从库的过期键处理依靠主服务器控制，主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。
  ```

  



* 跳跃表

  ```
  https://zhuanlan.zhihu.com/p/23370124
  ```

* 为什么用跳跃表不用平衡树，不用hash 表

  ```
  不和b+树比较是，b+树是工程树，在平衡树的基础上演变出来的
  
  不用hash 表，是因为不方便范围查询。（根据value 获取值是通过hash 表）
  
  1.相比较平衡树 （比如红黑树， 二叉树）， 更矮， 时间复杂度 lognM, 加入结点，只需要修改指针就好了，自平衡的代价更低
  2.指针更少。平衡树 2n 个指针， 跳跃表 1/(1-p) 个指针
  
  ```



* 网络模型

  ```
  https://zhuanlan.zhihu.com/p/54580385
  
  1.阻塞io
  2.非阻塞io （不阻塞，一直询问）
  3.多路复用 （主要一个线程可以监听多个fd， 非阻塞，事件通知）
  4.信号驱动io
  5.异步io （真正意义上的非阻塞）
  ```

* redis 6.0x 多线程为什么应用不广泛

  ```
  多线程主要是解析命令和 拼凑结果到response 中
  
  相比较单线程，这块的提升，可能代价比较大，相较于 多核机器上部署多个redis 实例，和 多核机器上部署单个redis 实例，又或者是 单个redis 实例因为是多线程，需要上下文切换，不划算。
  ```

* redis 怎么接受处理命令的

  ```
  1.redis 网络模型，非阻塞io 多路复用，多个fd 存在于netpool 中，当fd 有read write 事件的时候会主动通知主线程去处理请求。请求会被写到队列中，被redis 的命令处理器处理，命令处理器分发命令，比如建立连接的请求和 查询修改的请求。
  2.redis 的多线程主要在于解析命令和 拼凑结果到返回response 上。
  ```

* redis 设置过期时间

  ```
  expire
  
  pexpire 可以设置毫秒，很少用
  
  expireat ， 具体某个时间过期，感觉这样可以防止 设置 ttl 有问题的情况， 也很少用。
  
  pexpireat。
  
  set key value  ex n
  
  set key value px n
  
  判断 key 是否存在
  
  
  ttl key。
  -2 不存在
  -1 没有过期时间
  n n秒后过期
  
  
  每当我们给一个key 设置过期时间时候，会把这个key 带上过期时间放到一个过期字典中，
  ```

​    ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230128154818.png)

  redis 判断 key 是否过期。



* 过期键的删除策略

  ```
  1.惰性删除。使用key时才进行检查，如果已经过期，则删除。
  缺点：过期的key如果没有被访问到，一直无法删除，一直占用内存，造成空间浪费。
  
  2.定期删除。每隔一段时间（可配置）做一次检查，删除过期的key，每次只是随机取一些key（可配置）去检查（过期字典中）。
  
  3.定时删除。为每个key设置过期时间，同时创建一个定时器。一旦到期，立即执行删除。缺点：如果过期键比较多时，占用CPU较多，对服务的性能有很大影响。
  
  
  ```

  <img src="https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230128155053.png" style="zoom:50%;" />

  

* redis 数据满的时候怎么删除键。 内存淘汰策略

  ```
  首先是不进行数据淘汰 和进行数据淘汰 两大类。
  
  1.不进行数据淘汰，数据满了，可以查，但不能增加，增加就会 oom.
  
  2.进行数据淘汰，分成
  
  对有过期时间和无过期时间的。
  
  有过期时间
  1. 随机
  2. 最近要过期的淘汰。
  3. lru （传统的要大链表，redis 每个key 存一下最近使用时间，然后随机选出一批数据，比对最近使用时间进行淘汰）
  4. lfu （并不单单记录使用次数，而是通过一个值，先按照上次访问距离当前的时长，来对 logc 进行衰减，然后，再按照一定概率增加 logc 的值）(因为频率太难维护了，需要时间和总数。我们核心只需要维护一个可以替代频率的数字)
  ```

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230128155144.png)



* list hash，set， zset 都是容器。这些容器在元素为空的时候会被自动回收

  ```
  除了 string ，的set 能带有过期时间，剩下的操作都要单独 expire 设置时间。
  ```

* Redis 突然挂了怎么办

  ```
  1、从系统可用性角度思考，Redis Cluster引入主备机制，当主节点挂了后，自动切换到备用节点，继续提供服务。
  
  2、Client端引入本地缓存，通过开关切换，避免Redis突然挂掉，高并发流量把数据库打挂。（第二种基本不考虑）
  ```

* Redis 分布式锁

  ```
  1. 核心 setnx 和 expire 指令的统一，出现了 set 指令添加参数。即使这样也可能在expire 阶段出现死锁， 核心就是 expire 时间足够短。 （set 指令，nx not exist 才设置， ex 超时设置）
  2. 如果expire 太短，执行任务过久，锁失效了怎么办。可以启动一个goroutine 主动去续约锁 （看门狗的作用）（续约）到期关闭ticker。
  3. 为了防止别人删除你的锁。可以通过 唯一键 来设置值，删除前先通过lua 脚本获取值 ，是否相等，相等再删除。（get compare delete）
  
  ```

* 分布式锁在主从和 redis-cluster 中会有什么问题

  ```
  主从延迟。
  
  cluster 主节点挂掉，从节点顶上，也是主从延迟问题。
  
  redlock, 设置多个key， 一般以上成功就是成功。 不同节点上服务器时钟偏移问题。刚好设置3个成功， 判断是否过期的时候，其中一个因为时钟跳动，显示过期了，但实际没有过期。
  ```

* 用 Redis 做缓存有遇到什么问题吗？

  ```
  大key， 导致的高流出。拆分key 去缓解。
  
  热key， 本地缓存 和 single flight 去缓解。
  ```

  





* Redis hyperloglog （额外的结构）

  ```
  统计uv
  
  工作中的使用 :
  
  之前在做商品口碑数据的爬取的时候，我们消费者每天从kafka 中消费商品链接，产品希望知道每天爬取的商品数有多少，来评估口碑对商品的影响程度是否足够，之前是我们每次更新商品链接的时候会对这条记录修改抓取时间，后来商品方觉得这个字段没有必要，不允许更新，我们没法通过 更新时间去统计，而且通过更新时间去count 也比较慢，所以使用了redis 的 hyperloglog。
  
  两个指令 （pfadd, pfcount, pfmerge 对于cluster 的使用不支持， 可以试试 hash tag）
  
  （cluster 对于 mget， pipline 等这些多key 操作都 不是很好, 可以用hash tag）。
  
  (上述场景，有bitmap ，hashmap 都可以 做到，但是hyperloglog 在大批量数据的时候内存固定 12k)
  
  （存在误差）
  ```

  

* Redis 布隆过滤器

  ```
  工作中的使用：
  
  外部商城在公司app上投放广告。产品的需求是今天某用户点击，这个广告后面依旧展示( 红包)， 但是变灰了。如果每个用户记录条数据，数据太多，没必要。可以对用户行为设置成bitmap， 展示前先查询下（hash key 是用户id），如果 true， 展示灰色， 否则展示原色。（这个bitmap 不属于布隆过滤器）
  
  （qps 低， 300多）
  
  原理： 
  多次hash， 没有一个重复值，就是不存在。
  
  可能出现hash 冲突，导致误判 (没有点击，也变灰了)
  
  其实最好还是不要用bitmap， 这种一个key， 感觉容易造成大key， uid 也很大，占用的位数也很大。
  
  更适合用户维度的签到。
  ```


* Redis  简单限流

  ```
  zset  ， score 是时间戳， zrange 获取 set 内容。
  
  1.延迟队列也可以使用 zset 去实现， 同样score 是时间戳 ， 这个时间戳不是当前时间，而是当前时间 + 延迟时间， 用脚本定时轮训。
  
  2.主要用在排行榜。
  
  single flight 减少 热key 的存在
  ```

  

* Redis Geo

  ```
  底层 zset ，但是容易出现大key。
  ```

  

* 大 key 的坏处

  ```
  1.扩容的时候申请更大的内存空间。
  
  2.客户端超时阻塞，阻塞工作线程。
  
  3.网络阻塞。redis 操作很快，对于大vlaue 的频繁读取，很消耗网络带宽。 1m 一个key， qps 1000， 1000m/s, 网卡压力过大
  
  4.大key 负载不均衡，有的节点内存占用高。
  
  5.aof， rdb fork 子进程去备份数据，如果有数据修改，会 copy on write，耗时过长，fork master 进程
  
  ```

  

* Redis 设计一个秒杀系统

```
https://tech.antfin.com/docs/2/63920

1. 准备阶段， 大量的请求。静态资源 cdn 缓存，浏览器缓存。 动态资源 api 返回数据， 类似商品图片地址，可以走 网关缓存，比如 kong 那边直接返回，请求不进入 后端服务。商品数量这种实时性有要求的，可以通过 single flight 减少对后端服务的压力。
2. 秒杀阶段。 
   秒杀开始结束时间，机器内存缓存一份。
   是否秒杀完，机器内存缓存一份。
   
   利用lua 脚本执行的 原子性。 先定义一个 struct， 分别有 
   1.秒杀是否开始 （可以给客户端一个时间，让客户端自己先判断，如果有请求来我们这边，我们也加上一个判断。 客户端点击后到有返回，都是灰色，不能再点，服务端也加一个分布式锁）。
   2.秒杀总量。 
   3.当前秒杀量。 当前秒杀 + 1 <= 库存，就可以下单
3. 后续阶段。 成功后把抢到秒杀的人放入消息队列中，异步处理数据。
4. 比如 rds 只能抗住10w qps， 我们 100w qps， 可以通过分片去降低压力。

```



* Redis 大key 解决方案

```
1.单个简单key的存储的value过大的解决方案：

（类似我们金刚位）将大key拆分成对个key-value，使用multiGet方法获得值 (注意这快要是 multi get， 事务的话会阻塞 redis 的执行效率， 但又要注意 现在的分布式 redis， multiget 获得的key 可能在不同的集群上，所以网络io 肯能要多次网络io)，这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的IO操作。

2. string， hash、set、zset、list中存储过多的元素的解决方案：

1).类似于第一种场景，使用第一种方案拆分; （比如hash， 根据 field， 先hash， 再去对应的key 中查询）

2) string， 转hash。每次只获取部分数据。
```

* redis 热key 处理

  ```
  1.单个key 生成多个 key， 分布不同节点上
  2.本地缓存
  3.single flight 降低服务器压力
  ```

* redis 集群方案

  1.主从 （手动切换），没办法水平扩容

  2.哨兵模式。只是引入了哨兵机制，依旧没办法水平扩容

  3.cluster 模式，去中心化。保证高可用，副本 （节点间的数据同步并没有用到zookeeper， 而是使用redis 自己的协议，发送心跳包）

* Redis 集群同步数据

```
1、slave启动后，向master发送sync命令
2、master收到sync之后，执行bgsave保存快照，生成RDB全量文件 （类似可重复读，所以rdb文件是开始执行时候的样子，利用类似aof机制，保证生成rdb 文件期间所有命令被记录）
3、master把写命令记录到缓存
4、bgsave执行完毕之后，发送RDB文件到slave，slave执行
5、master发送缓冲区的写命令给slave，slave接收命令并执行，完成复制初始化。
6、此后，master每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性
```

https://mp.weixin.qq.com/s/RRVCJS_X60ugA_52h38TBA

* redis 怎么做扩容

  ```
  为了避免数据迁移失效，通常使用一致性哈希实现动态扩容缩容，有效减少需要迁移的Key数量。
  
  但是Cluster 模式，采用固定Slot槽位方式（16384个），对每个key计算CRC16值，然后对16384取模，然后根据slot值找到目标机器，扩容时，我们只需要迁移一部分的slot到新节点即可
  ```

* 为啥是16384 slot

  ```
  太多了，心跳包太大
  ```

* redis 集群原理

  ```
  一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，组成一个集群。
  
  数据存储通过分片的形式，整个集群分成了16384个slot，每个节点负责一部分槽位。整个槽位的信息会同步到所有节点中。
  
  key与slot的映射关系：
  
  健值对 key，进行 CRC16 计算，计算出一个 16 bit 的值
  将 16 bit 的值对 16384 取模，得到 0 ～ 16383 的数表示 key 对应的哈希槽
  ```

  

* redis 持久化原理和优化

  aof 过程

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20230128193102.png)

  这样还是会存在写完命令后，如果redis 宕机了，日志文件的丢失。

  写 aof 是放在 执行命令前，还是后 ？

  肯定是放在后，因为可能执行命令失败，这时候不用写日志， 还有不会阻塞 redis 命令，但会阻塞下一条命令。

  ```
  aof:记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。(指令) 
  
  三种会写策略：
  1.每秒执行 （Everysec）
  2.每条命令执行 （always）
  3.系统内核调度 (no)。
  
  aof 重写策略。
  
  如果aof 文件过大，会通过命令合并，减小 aof 文件体积。
  
  这里说一下为什么重写 AOF 的时候，不直接复用现有的 AOF 文件，而是先写到新的 AOF 文件再覆盖过去。
  因为如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染，可能无法用于恢复使用。
  所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。
  
  aof 重写，是通过后台新的进程  bgrewriteaof 来完成的。
  
  aof 重写 （感觉是对aof 文件），
  因为是类似 key-value 的文件，如果对已经完成的 key-value ，就是需要 aof 重写缓冲区。
  对未完成key-value ,就是需要 aof 缓冲区。
  
  
  
  
  rdb:在指定的时间间隔能对你的数据进行快照存储。（数据库内容， 二进制文件）
  
  执行频率：
  多少次写入操作执行。
  例：
  900 秒之内，对数据库进行了至少 1 次修改；
  300 秒之内，对数据库进行了至少 10 次修改；
  60 秒之内，对数据库进行了至少 10000 次修改。
  
  1.save （阻塞）
  2. 调用bgsave 
  
  一般数据恢复，靠rdb 打底， aof 恢复近期数据
  
  rdb 执行期间，如果数据被修改， rdb 保存的是修改之前的数据
  ```

* redis 大key 对持久化的影响

  ```
  1.aof 写过程中，如果是 always 类型 （没写一条命令都会同步aof），大的key 同步aof 比较慢。 everysec 和 no 不受影响。
  
  2.aof 重写过程， 或者 rdb 过程，因为存在 fork 子进程，页的copy ，数据越大，copy 花费时间越长。copy 过程会阻塞主进程 （单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回）。
  
  3.写时复制，如果大key 被修改，copy 过程过长 ，也会阻塞主进程。
  
  ```

  



* redis 的哪些特性

  ```
  1.性能高， 读的速度是100000次/s，写的速度是80000次/s
  2. 数据持久化，支持RDB 、AOF
  3. 支持事务。通过MULTI和EXEC指令包起来。(期间会阻塞别的指令)
  4.多种数据结构类型
  5.主从复制
  6. 其他特性：发布/订阅、通知、key过期等
  ```



* redis 为什么这么快

  ```
  https://cloud.tencent.com/developer/article/1745894
  
  1.完全基于内存，没有磁盘IO上的开销，异步持久化除外。
  2.单线程，避免多个线程切换的性能损耗，也避免了多线程可能产生的竞争问题，底层数据也不用加锁 。redis 速度的核心是网络io 和 内存大小。
  3. IO多路复用机制 和 非阻塞 io。（poll）
  4. 底层的数据存储结构优化，使用原生的数据结构提升性能。比如 string 底层是 sds， 对于len 方法o(1)的复杂度。 队列 quicklist， list + 压缩列表组成，而且还有头尾指针，对于两边操作很快， 。
  ```

* Redis 网络 io 模型

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/ofen8xlxqk的副本.png)

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/pra9wx9r05的副本.png)

  ```
  https://cloud.tencent.com/developer/article/1790992
  
  6.x 之前是 单线程 reactor 模型。 
  
  之后是 多线程模型
  
  4.x
  
  socket -> i/o multi 多路复用 -》 解析客户端参数->处理任务-> 回写数据
  
  6.x
  
  socket--> i/o 多路复用 --> 多线程解析客户端参数 --》写入队列--》处理任务--》多线程回写数据给客户端
  
  ```

* redis 的 rehash 过程，如果断电会怎么样

  ```
   ht[0]，是存放数据的table
   ht[1]，只有正在进行扩容时才会使用，它也是存放数据的table，长度为ht[0]的两倍
   进行读操作：比较当前key的大小和 rehashidx的大小，来选择
   进行写操作：直接写在ht[1]中。
   rehashidx 初始是-1，开始rehash则为0，每次rehash都+1，
   rehash结束则修改为-1
  ```

  

* redis cluster 结构

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20210920000352.png)

  
  
  

* redis 雪崩，穿透，击穿

  ```
  雪崩。 （大量 key同时过期，初期项目上线）
  1.随机值给上，本来缓存的存在就是可能存在误差。
  2.回源数据利用 single flight。防止 db 回源压力过大
  
  
  
  穿透。（热点数据过期）
  1. single flight 。
  2. 本地缓存
  
  
  击穿。（数据不存在， 可能一异常刷子，可能是有缓存的数据本身就比较少）
  1. single flight + 空缓存
  2. 异常ip 的封禁
  3. 布隆过滤器 （大航海，减少无效的qps）
  ```

* redis 实现分布式锁

  ```
  1.加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁
  
  2.锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
  
  3.锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；(lua compare and delete)
  
  4.锁过期时间的续约
  
  5.为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。
  ```

* redis 事务支持回滚吗

  ```
  Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。
  
  案例一：
  #获取name原本的值
  127.0.0.1:6379> GET name
  "xiaolin"
  #开启事务
  127.0.0.1:6379> MULTI
  OK
  #设置新值
  127.0.0.1:6379(TX)> SET name xialincoding
  QUEUED
  #注意，这条命令是错误的
  # expire 过期时间正确来说是数字，并不是‘10s’字符串，但是还是入队成功了
  127.0.0.1:6379(TX)> EXPIRE name 10s  // 并没有检查出来
  QUEUED
  #提交事务，执行报错
  #可以看到 set 执行成功，而 expire 执行错误。
  127.0.0.1:6379(TX)> EXEC
  1) OK
  2) (error) ERR value is not an integer or out of range
  #可以看到，name 还是被设置为新值了
  127.0.0.1:6379> GET name
  "xialincoding"
  
  
  案例二：
  #读取 count 的值4
  127.0.0.1:6379> GET count
  "1"
  #开启事务
  127.0.0.1:6379> MULTI 
  OK
  #发送事务的第一个操作，对count减1
  127.0.0.1:6379> DECR count
  QUEUED
  #执行DISCARD命令，主动放弃事务
  127.0.0.1:6379> DISCARD  // queue 队列被抛弃，并没有执行完
  OK
  #再次读取a:stock的值，值没有被修改
  127.0.0.1:6379> GET count
  "1"
  ```

* redis 管道

  ```
  客户端的一种技术。
  pipline，
  减少了网络请求
  ```

  

* redis 做队列，如果消费者挂掉了，这个数据丢失了怎么办

  ```
  不管是 list 还是 pub sub 这种模式， 都会丢数据
  
  list 没有确认机制， pub sub 只是转换数据，并没有实际的空间存储数据， 所以不要用
  
  最新的stream （内存型） 需要ack，但一般都用kafka ，rabbit， rocket
  ```

* bitmap 多大

  ```
  bitmap 底层是 string， string  512 m，  9 + 10 + 10 + 3  =32， 2 的32 次方
  ```

* bitmap 缺点

  ```
  统计时候的时间复杂度 o(n)
  ```

* 为什么用跳跃表不用红黑树

  ```
  1.红黑树 二叉树，太高
  2.红黑树不容易做范围查询(不容易，但也可以，中序遍历)，跳跃表最下面一层是双向链表 
  3.红黑树自平衡麻烦，跳跃表最多只是相邻节点的变动
  ```

  

  

* select poll epoll 的区别

  ```
  fd 文件集合 读，写 ，异常fd
  
  select， 遍历 fd 集合，时间复杂度 o(n), 上限1024
  poll 改了存储结构， 依旧轮训，复杂度 o(n), 上限 1024
  epoll 事件轮训机制，可以监听到具体某个 fd 改变。
  ```

  

  

  

  
  
  
