K8s 的服务注册

```
```



整体业务的架构, 服务之间的通信方式，信息处理

```
```



k8s的请求怎么转发到内部实际的ip， 服务之间的通信

```
1）Service就是一个把所有Pod统一成一个组，然后对外提供固定一个IP，
    （2）我们访问service ip，k8s中的kube-proxy会自动负载均衡后端的8个pod,
    这一套服务集群内部访问，只需要一个service ip 和端口号就可以
    （3）外网访问：在每个Node上打开一个随机端口并且每个Node的端口都是一样的，
    通过<NodeIP>:NodePort的方式Kubernetes集群外部的程序可以访问Service。
        访问到service之后，自然也就能找到对应的pod提供服务了
    （4）.ClusterIP：提供一个集群内部的虚拟IP（与Pod不在同一网段)，
        以供集群内部的pod之间通信使用。
    （5）生产环境下的外网访问：
    Ingress 能把集群内 Service 配置成外网能够访问的 URL，流量负载均衡，
        终止SSL，提供基于域名访问的虚拟主机等等。
        1）Nginx 反向代理负载均衡器
        2）Ingress Controller
        Ingress Controller 可以理解为控制器，它通过不断的跟 Kubernetes API
         交互，实时获取后端 Service、Pod 等的变化，比如新增、删除等，
         然后结合 Ingress 定义的规则生成配置，然后动态更新上边的 Nginx 
         负载均衡器，并刷新使配置生效，来达到服务自动发现的作用。
        3）Ingress
        Ingress 则是定义规则，通过它定义某个域名的请求过来之后转发到集群中指定的
         Service。它可以通过 Yaml 文件定义，可以给一个或多个 Service 定义一个
         或多个 Ingress 规则。
```



* 服务限流怎么做到的？服务熔断怎么做到的？

  ```
  限流：（1）代码里的队列计数
      redis-cell是一个用rust语言编写的基于令牌桶算法的的限流模块，
      提供原子性的限流功能，并允许突发流量，可以很方便的应用于分布式环境中
      
          （2）网关限流
          nginx自带的ngx_http_limit_req_module模块是对请求进行限流，
          即限制某一时间段内用户的请求速率；且使用的是漏桶算法
          
          
     熔断：熔断就是用php扩展滑动窗口计数
         滑动窗口算法限流最适合的需求场景，就是X秒内，最多允许Y个请求
  ```

* 为什么要引入分布式 （优点）

  ```
  （单点故障造成全局故障）为了解决传统单体服务架构带来的各种问题，代码数量庞大，迭代测试维护困难，可能因为一处改动测试不到位造成整个服务瘫痪等问题。分布式存储在遇见单点故障时很容易造成整个服务不可用，分布式下的服务体系，单台机器有故障，不致于造成整个服务不可用。
  
  代码不在一个项目里，也不会冲突，最主要的是项目自己维护，多好。
  
  方便扩容。（比如大促的时候并不是所有部分都需要扩容）
  ```

* 分布式 缺点

  ```
  维护成本高 （运维累） 开发成本高（开发的时候多个编辑器疯狂切换）
  
  分布式依赖网络通信。
  
  ```

* rpc 的 架构

![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20210919192924.png)

```
1.服务集成 RPC 后，服务（这里的服务就是图中的 Provider，服务提供者）启动后会通过 Register（注册）模块，把服务的唯一 ID 和 IP 地址，端口信息等注册到 RPC 框架注册中心（图中的 Registry 部分）。
2. 当调用者（Consumer）想要调用服务的时候，通过 Provider 注册时的的服务唯一 ID 去注册中心查找在线可供调用的服务，返回一个 IP 列表
3.notify 部分。第三步 Consumer 根据一定的策略，比如随机 or 轮训从 Registry 返回的可用 IP 列表真正调用服务
4.invoke
5.最后是统计功能，RPC 框架都提供监控功能，监控服务健康状况，控制服务线上扩展和上下线
```



* 服务启动的时候服务基本信息被注册到注册中心，如果服务提供者挂了，注册中心如何知道服务不可用

  ```
  服务掉线分为主动下线和心跳检测，比如服务由于发版时，在重启之前先主动通知注册中心：我要重启了，有流量进来先不要分给我，让别的机器服务，等我重启成功后在放流量进来，或者是在管理后台手动直接摘掉机器，这个是主动下线。
  
  心跳检测是处理服务非正常下线（如断电断网）的情况，这个时候如果注册中心不知道该服务已经掉线，一旦被其调用就会带来问题。为了避免出现这样的情况，注册中心增加一个心跳检测功能，它会对服务提供者（Provider）进行心跳检测，比如每隔 30s 发送一个心跳，如果三次心跳结果都没有返回值，就认为该服务已下线，赶紧更新 Consumer 的服务列表，告诉 Consumer 调用别的机器。
  ```

* 如果你用的是 zookeeper， 如果zookeeper 挂了，服务之间还能相互调用么

  ```
  首先注册中心挂掉也要分两种情况，
  1.(数据库有问题)如果数据库挂了，ZK 还是能用的，因为 ZK 会缓存注册机列表在缓存里。
  
  2. （zk 某个节点有问题）ZK 本身就是一个集群的，一台机器挂了，ZK 会选举出集群中的其他机器作为 Master 继续提供服务，
  
  3.如果整个集群都挂了也没问题，因为调用者本地会缓存注册中心获取的服务列表。省略和注册中心的交互，Consumer 和 Provider 采用直连方式，这些策略都是可配置的。
  ```

* 画一个rpc 框架

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20210919193840.png)

```
1.客户端 invoke 方法编写，使用 JDK 的动态代理技术，客户端调用远程服务方法时调用的是 InvocationHandler 的 invoke 方法。
2.客户端 Filter 方法编写，完善的 RPC 框架少不了监控、路由、降级、鉴权等功能。
3. 创建 Socket，在 Filter 方法中实现 Client.write 方法，其逻辑为从连接池（ChannelPool）中获取连接，然后将数据写进 Channel。
4. 实现数据序列化、压缩，目的减少网络传输的数据量，向服务端发送 request 数据，这里可以使用 Netty 异步通讯框架。
5. 服务端收到客户端发过的消息后，从 Channel 中将消息读出来之前，也会先经反序列化解压。
6. 请求就到了服务端 Filter 中。请求依次经过监控、鉴权方法。
7. 根据客户端传递来的服务信息和参数，通过反射调用相应的业务服务并拿到业务处理结果。然后在 ResponseFilter 中将返回结果写入 Channel。
8.服务端序列化、压缩等，发送给客户端。
9. 客户端收到消息后，经过客户端反序列化、解压缩，后交给 ResponseThreadPoolProcessor 线程池处理。
ResponseThreadPoolProcessor 收到消息后，就将结果返回给之前的方法调用，整个调用请求就结束了。
```



* redis cluster 架构

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/20210919194616.png)

cap 理论同时只能满足两个



* 正向代理，反向代理

  ```
  生活中的正向代理，打个比方，你想去美国旅行，需要去使馆办理签证，手续麻烦，你完全不知道从何下手，这个时候你想到找旅行社，有专门的导游可你帮你代办，你只需提供资料就在家等着拿签证就可以了，你是客户端，美国使馆是服务端，导游就是代理端。服务器架构中正向代理也很容易理解，如果使用 Google，需要用的一些工具，这就是一个典型的正向代理。
  
  互联网不够发达的时候，我们都打过 10086，有事儿就找客服，全国 31 个省都有自己的客服中心，每个客服中心都有上百个客服小哥小姐姐，我们不关心给你分配的是谁，只需要接通 10086 后会自动给你分配客服给你，这就是反向代理。
  ```

* 常用的负载均衡算法

  ```
  轮训
  
  加权轮训
  
  随机
  
  最小连接数
  
  hash 算法
  
  一致性hash
  ```

  

* docker 相关

  ![](https://cytuchuang-1256930988.cos.ap-shanghai.myqcloud.com/img/5f1684e100017c4e08700422.png)

  ```
  client （客户端）
  
  daemon （服务端运行的常驻内存）
  
  images  （程序code）
  
  container （程序code 运行起来的 app）
  
  registry （镜像中心）
  ```

* 常用指令

  ```
  docker run -it centos:latest /bin/bash
  
  常用参数  -d  daemon 运行
  
  -p port 映射（docker 都是 宿主: 容器）
  
  --name  给 container 取以一个名字
  
  docker attach （不能exit）
  
  docker exec -it  centos:latest （可以 exit）
  
  docker ps  查看运行的容器
  
  docker kill containId
  
  docker log containId
  
  docker top containId
  
  docker images
  
  docker build （image 打 tag）
  
  docker commit  
  上面说到我们可以通过一个 Dockerfile 构建出镜像，但是有时候我们在使用过程中对容器（container）做了一些改动，比如安装了一些依赖包。我们想把这些改动保存下来形成新的镜像，同时不想再去编写 Dockerfile，或者之前的 Dockerfile 我们没有。那么这时候我们就可以通过 docker commit 将一个 container 的环境持久成镜像。我们首先看一下 docker commit 的使用规范说明。
  
  
  docker history （docker images 构建历史， 上面的 commit 历史）
  
  docker  save 
  
  有这么一种场景，有时候我们要将一台机器的本地镜像导入到另外一台机器，当然你可以将镜像先 push 到镜像仓库中心，然后另外一个机器再进行 pull。但是有的时候由于镜像的安全性或者镜像比较大，不是很适合这种先 push 再 pull 的场景，那么我们就可以将镜像先导出成压缩文件，然后再将压缩文件导入到另外一个机器。其中镜像导出成压缩文件，就是 docker save 做的事情。
  
  docker  import
  
  docker load，
  
  docker  rmi
  
  ```

* 服务注册与发现，微服务的监控，微服务的限流相关，守护进程

  ```
  ```

* 批量生成几十万或者上百万的兑换码

  ```
  ```

* 写一个方法，解决：输入 4 个数字，通过加减乘除，输出一个期望值。
  广度优先算法：怎么输出各层的值。
  台阶问题，假如对于上台阶，可以一次上一阶，也可以一次上两阶，写一个方法，实现输入台阶数，输出可以有多少种上法。

* linux 熟悉的命令有哪些

  ```
  ps -ef
  top
  df -h
  lsof -p
  touch 
  ls
  cd
  cp
  mv
  tail -f 
  chmod
  ```

* 如果线上流量暴增，全都打到一个 upstream 上了，怎么排查。

  ```
  ```

* 如何在 nginx 的 access log 中查出请求前 10 的 ip

  ```
  ```

  
