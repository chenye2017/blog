* 为什么有些人称kafka ， rabbitmq 这些为 mq框架 

  ```
  我们刚开始写代码的时候会把 tp， laravel，gin 这些称作框架，理解的意思就是用某种语言封装了一些通用方法，搭建了项目骨架 Skelton，帮助我们更快更方便的写代码。我们写的项目基本上都是以一个框架为主题，然后扩展其中的某个文件夹。这种想法会在我们心中有个先入为主的概念，不能理解一款mq 为什么可以称之为消息框架，难道有人用kafka 做项目 ？
  其实我们做项目的时候，tp， laravel gin 这些更类似于组件 components，他们是项目的附属品而不是主体， 我们的 项目中可以既 集成了 tp ，也集成laravel （因为二者有对相同功能的封装，这样做很浪费，所以一般不会这么做），那是不是 kafka 我们也可以称之为组件。是这样的，但我们代码中一般集成的我们代码语言编写的 客户端sdk ，他和 kafka 这些软件本质上没有多少关系，其实就是为了连接他们，发送请求，符合kafka 的协议写的一种 收发器。（kafka， redis， mysql 其实本质上都是一样的， 他们都属于一种中间件，一种 语言写的软件，我们平时的代码中集成的是 一些人为其写的接入 客户端，比如如何建立tcp 连接，如何 收发消息）。
  ```

 

* rabbitmq 和 kafka 的区别

  ```
  rabbitmq 内存型， 队列模型， 如果有多个消费者，会有多个消费队列，数据冗余
  
  kafka 发布订阅模式。
  
  
  
  rabbitmq 推消息， 一次性推一条。
  
  kafka 数据写入 磁盘， 拉消息，一次性可以拉多条。
  ```

  



* mq 的使用场景

  ```
  mq 一般用在异步的场景。比如购买大航海，给用户加上大航海身份是最核心场景，给用户附带赠送app 装扮，下发开通动画是非核心场景，这些非核心场景尽可能和核心场景解耦开，可以保证核心场景的可用率。
  
  所以mq 的一个作用，解耦就体现出来了。
  
  但异步的执行又可以有两种方式实现，一种是mq， 另一种是多协程。
  
  mq 延迟比较高，一方面是消息的传递 （producer -> broker -> consumer）, 消费还可能积压， 进一步提升延迟。所以对于下发开通动画这种延迟要求比较高的可以考虑用多协程，在b站内部开发了一个小的组件，功能本身也就是 生产-》消费模型，存储用的channel， 定义一个最大 buff，多个worker 常驻去消费 生产者生产的消息，因为是基于本地内存的，所以需要兼容平滑重启，比如发布的时候。接收到服务器要重启的信号（可能是channel 信号，可能是同步执行），会调用组件自身的cancel 方法，让组件当前处于一个关闭的状态。  再就是发送 一个 channel 元素，这个元素让consumer 收到的时候能自我结束。（其实也可以主动关闭channel， 但一定要保证此时没有元素还能进来了，fanout 使用的方法就是 在 塞元素进入channel 前，先判断 组件的 ctx.Err 是否存在，如果存在，就不往里面塞数据了）
  
  还有对于mq 自身的发送，我们也是放在多协程中。
  
  但mq 也有它自身的优势，比如
  
  1.一条消息能被多个消费者订阅消费
  2.基于磁盘，可以积压，可以水平扩展。
  3.对于kafka ，可以通过offset 的变更，达到消息重放的作用。
  
  
  1.削峰填谷（下游自己拉数据）。缓冲上下游瞬时突发流量，保护“脆弱”的下游系统不被压垮，避免引发全链路服务“雪崩”。（口碑项目保护算法提取关键词。
  2. 复用 （多个消费者）。返现项目主要是外部公司暴露出去的一般用的都是api 项目，比如我们要获取订单，都是通过一个地方 job 拉订单，然后放到消息队列中，让各个业务方自行订阅消费）
  3.系统解耦。发送方和接收方的松耦合，一定程度简化了开发成本，减少了系统间不必要的直接依赖。(微服务)发布订阅模式。 （依赖方的重构，域名 or 路由名  or http -> rpc 的改变，相比较 msg 结果可能更加不会改变）
  4.异步处理 （不影响主流程）。
  ```

* Mq 的问题

  ```
  1.消息丢失问题
  
  2.消息顺序问题
  
  3.消息重复问题
  
  4.一致性问题
  ```
  
  
  
  
  
* mq 的消息顺序问题，如何解决 （一般情况下我们认为只要保证局部有序就可以（单个partition有序）， 不需要全局有序）

  ```
  1.保证局部有序，mq 组件会自己先保证能提供大部分场景下数据的一致性。比如kafka 我们在发送消息的时候实则 msg 的key， 让其消息在正常情况下都路由到同一个partition 上。（路由规则的场景使用很多，比如负载均衡 (常见的)，常用的有hash， random， 顺序，权重）。
  
  2.再根据我们 记录变动的时候存储的 消息时间 （业务侧），保证 先产生的消息一定不会在 后产生的消息之前执行，如果存在，直接丢弃，记录异常。
  
  3.同步发送， （异步发送可能失败了重试），单生产者，单消费者 （需要保证生产者和消费者都是 顺序的，比较难）
  ```
  
* Mq 的消息重复问题，如何解决

  ```
  消息的重复问题很难避免。
  生产者，如果异步通知因为网络原因没有收到，再次发送，导致生产消息重复。
  消费者，如果消费者挂了，另一个消费者顶上，比如服务重启，因为 offset 没有提交，消息又会重复
  
  
  遇到的情况
  
  感觉我们的消息重复问题应该是平滑重启导致。 程序监听到 信号，重新启动一个新的进程处理脚本任务，老的脚本停止停止流量进入，关闭。但是这个中间时间可能有老的消费者和新的消费者都存在（offset后置提交），所以导致了消息重复消费。
  
  
  1.存储层做唯一索引，保证并发安全。
  
  2.redis 锁
  
  ```

  

  kafka 是怎么保证不丢失的

  ```
  1.生产者。
    同步发送，并对结果进行判断，如果失败了就重试。
    或者异步发送，callback 通知有没有发送成功
  
  2.broker。 自身有多副本形式，如果一条消息发送到broker， leader挂掉，还没有来得及同步follower,消息就会丢失。解决方案便是再给生产者返回发送成功的消息之前，需要确定消息至少同步到了一个follower中再返回，当然，如果业务场景非常重要，则可以配置acks=all，但是牺牲的是性能
  
  3.消费者丢消息。（https://dengchengchao.com/?p=1307）
  步骤：
  1.消费者主动调用poll()方法拉取消息
  2.消费者拉取消息后，主动上报目前的消费进度到Broker端
  3.Broker端收到消费进度后，将该分区的消费进度持久化
  
  消费完手动提交。
  ```





* kafka 消息是采用pull 模式，还是 push 模式

  ```
  生产消息 push
  
  消费消息 pull。 如果是push， broker 需要考虑下游消费者的承载能力。
  
  pull 的缺点是没有消息的时候 一般情况下需要定期轮训，而且轮训间隔不好控制。kafka 可以让consumer 阻塞直到有消息过来。
  ```

* kafka 是否可以消费指定分区消息

  ```
  可以。
  
  向 broker 发出"fetch"请求去消费特定分区的消息，consumer
  指定消息在日志中的偏移量（offset），就可以消费从这个位置开始的消息，consumer 拥有
  了 offset 的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的
  ```

  

* 怎么实现一个延迟队列 ？？？？？

  ```
  队列中元素的数量。一定 （量小的话感觉是循环数组，量多的话感觉肯定不建议）
  
  往队列塞元素，元素的时间值。
  
  根据时间值。 consumer 每次取到数据，对比时间，如果比较早就sleep。 到点了就发动另一个消息队列。
  
  ```

* kakfa 发送消息

  ```
  1. 发送并忘记 (直接不管)。
  
  2. 同步发送 。
  
  3. 异步发送 + 回调函数。
  
  3 种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体使用哪种方式要看具体的业务场景，比如业务要求消息必须是按顺序发送，可以使用第 2 种同步发送，并且只能在一个 partation 上。如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式。如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步 + 回调的方式来发送消息
  ```



* kafka  partition 数量，broker 数量， consumer 数量， 副本数量

  ```
  partition 数量要最好不要多余broker 数量，否则容易造成 broker 负载不均衡，并不能提高系统吞吐。
  
  
  一个consumer 里面可能开多个协程去消费， 为了保证不提交大的offset， 一定要保证小的offset 被消费后再提交。
  
  （offset 提交一般都不是明确 offset 的具体值，而是单纯 +1）
  
  https://blog.51cto.com/u_12840595/4836375  伯约发出的灵魂拷问，后面的提交会覆盖前面的offset， 所以我们后面的offset 不要提交，但凡提交了，就证明你对这条消息不太看重了。
  
  https://blog.csdn.net/u010002184/article/details/113354392  副本数量和broker 数量的关系
  ```

  

* kafka  leader 副本， follower 副本

  ```
  之前一直在想 多副本机制，那有没有主体文件。
  
  现在感觉 leader 副本就是主体文件，对外提供读写服务。follower 数据用来冗余。
  
  副本数量 <= broker 数量，因为 follower 完全用来数据安全
  ```

  

* 顺序消息，如果某条失败了怎么办？ 会不会一直阻塞

  ```
  这个是否阻塞是自己决定的，如果一直不提交，就会阻塞。
  
  但正确的做法就是重试之后依然失败就 另外存储，在提交，不影响后面的消费。
  ```



* kafka 中的名词

  ```
  Broker：接收客户端发送过来的消息，对消息进行持久化
  主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。(消息的分类)
  分区：Partition。一个有序不变的消息序列。每个主题topic下可以有多个分区。
  消息：这里的消息就是指 Kafka 处理的主要对象。
  消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。（topic, consumer group, partition 决定一个offset）
  副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。每个分区可配置多个副本实现高可用。一个分区的N个副本一定在N个不同的Broker上。
  生产者：Producer。向主题发布新消息的应用程序。
  消费者：Consumer。从主题订阅新消息的应用程序。
  消费者位移：Consumer Offset。表示消费者消费进度，每个消费者都有自己的消费者位移。offset保存在broker端的内部topic中，不是在clients中保存 （如果保存在client 端，client 挂掉了，或者重新发布了，offset 就消失了）
  消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
  重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区
  
  
  hw (high water) （之后的日志消费者看不见，只有所有的follower 同步完，才能看见）
  leo (long end offset) （当前 leader 消息的最顶端）
  ```

  

* zookeeper 在里面的职责

  ```
  它是一个分布式协调框架，负责协调管理并保存 Kafka 集群的所有元数据信息，比如集群都有哪些 Broker 在运行、创建了哪些 Topic，每个 Topic 都有多少分区以及这些分区的 Leader 副本都在哪些机器上等信息, leader 副本的选举
  
  ```
  
* 消息传输的格式

  ```
  纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。
  
  http 协议， redis 协议 ，kafka 的消息协议，应该都是属于应用层的协议， 我们 的 客户端sdk 中要处理的这些协议包。对于 tcp 层粘包 拆包 属于 tcp 层，我们应该处理的比较少。
  ```

  

  

* 消息压缩

  ```
  生产者程序中配置compression.type 参数即表示启用指定类型的压缩算法。
  
  props.put(“compression.type”, “gzip”)，它表明该 Producer 的压缩算法使用的是GZIP。这样 Producer 启动后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。
  
  但如果Broker又指定了不同的压缩算法，如：Snappy，会将生产端的消息解压然后按自己的算法重新压缩。
  
  各压缩算法比较：吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；而在压缩比方面，zstd > LZ4 > GZIP > Snappy。
  
  kafka默认不指定压缩算法。
  ```

* 消息解压缩

  ```
  当 Consumer pull消息时，Broker 会原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。
  ```

* 生产者管理tcp 连接

  ```
  在new KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的连接。此时还不知道给哪个topic发消息，所以Producer 启动时会发起与所有的 Broker 的连接。
  
  Producer 通过metadata.max.age.ms 参数定期地去更新元数据信息，默认值是 300000，即 5 分钟，不管集群那边是否有变化，Producer 每 5 分钟都会强制刷新一次元数据以保证它是最新的数据
  ```
  
  

* producer 发送消息

  ```
  Producer 使用带回调通知的发送 API， producer.send(msg, callback)。
  
  设置 acks = all。Producer 的一个参数，表示所有副本都成功接收到消息，该消息才算是“已提交”，最高等级，acks的其它值说明。min.insync.replicas > 1，表示消息至少要被写入到多少个副本才算是“已提交”
  
  retries 是 Producer 的参数。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。
  
  之前用rabbitmq 发送消息，异步发送是等到 缓冲区满了，一次性 flush，所以是异步接受
  
  ```
  
* 幂等性 producer (虽然可以用， 但我们不使用，因为我们代码中可以做这些事，kafka 提供的这些功能可以帮助我们过滤掉一部分数据)

  ```
  https://www.cnblogs.com/smartloli/p/11922639.html
  
  设置参数props.put(“enable.idempotence”, ture)，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。
  
  原理很简单，就是经典的空间换时间，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，可以在后台默默地把它们“丢弃”掉。
  
  这个幂等性是在 broker 上的partition 做的
  
  只能保证单分区、单会话上的消息幂等性。一个幂等性 Producer 能够保证某个topic的一个分区上不出现重复消息，但无法实现多个分区的幂等性。比如采用轮询，下一次提交换了一个分区就无法解决
  ```

* 事务性producer  （基本不用）

  ```
  能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。能够保证跨分区、跨会话间的幂等性。
  
  实际上即使写入失败，Kafka 也会把它们写入到底层的日志中，也就是说 Consumer 还是会看到这些消息。要不要处理在 Consumer 端设置 isolation.level ，这个参数有两个值:
  
  read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息
  read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息
  ```

* kafka broker 是如何存储数据的

  ```
  Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。
  
  不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？
  
  简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
  ```

* kafka 的备份机制

  ```
  相同的数据拷贝到多台机器上。副本的数量是可以配置的。Kafka 中follow副本不会对外提供服务。
  
  副本的工作机制也很简单：生产者总是向leader副本写消息；而消费者总是从leader副本读消息。至于follow副本，它只做一件事：向leader副本以异步方式发送pull请求，请求leader把最新的消息同步给它，必然有一个时间窗口导致它和leader中的数据是不一致的，或者说它是落后于leader。
  ```
  
* 为什么要引入消费者组

  ```
  主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。
  
  在一个消费者组下，一个分区只能被一个消费者消费，但一个消费者可能被分配多个分区，因而在提交位移时也就能提交多个分区的位移。如果1个topic有2个分区，消费者组有3个消费者，有一个消费者将无法分配到任何分区，处于idle状态。
  
  理想情况下，Consumer 实例的数量应该等于该 Group 订阅topic（可能多个）的分区总数。
  ```

* 消费端offset 管理

  ```
  1）老版本的 Consumer组把位移保存在 ZooKeeper 中，但很快发现zk并不适合频繁的写更新。
  
  2）在新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer组的位移管理方式，采用了将位移保存在 Broker端的内部topic中，也称为“位移主题”，由kafka自己来管理。原理很简单， Consumer的位移数据作为一条条普通的 Kafka 消息，提交到__consumer_offsets 中。它的消息格式由 Kafka 自己定义，用户不能修改。位移主题的 Key 主要包括 3 部分内容：<Group ID，topic名，分区号 >
  
  topIC 分区号 用来区分 哪个topic， group id 用来区分 group
  
  Kafka Consumer 提交位移的方式有两种：自动提交位移和手动提交位移。
  
  Kafka 使用Compact策略来删除位移主题中的过期消息，避免该topic无限期膨胀。提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。
  ```

  

* rebalance 的触发条件

  ```
  1）组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，又或是有 Consumer 实例崩溃被“踢出”组。（99%原因是由它导致）
  
  2） 订阅topic数发生变更。Consumer Group 可以使用正则表达式的方式订阅topic，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的topic。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的topic，那么该 Group 就会发生 Rebalance。 (第二种用的少，因为我们自己的业务都是 自己生产，自己消费)
  
  3） 订阅topic的分区数发生变化。Kafka 目前只允许增加topic的分区数。当分区数增加时，也会触发订阅该topic的所有 Group 开启 Rebalance。
  
  4） partition 上消息数积压
  ```

  

  

* 历史数据清理 (有些问题虽然可能没遇见过，但可以自己想)

  ```
  基于保存时间，log.retention.hours
  
  基于日志大小的清理策略。通过log.retention.bytes控制
  
  两者满足其一就可以
  ```

  

* kafka 怎么保证消息不丢失

  ```
  发送的是否 保证消息不丢失
  1. 生产者 callback， 这个是告诉用户消息有没有丢失
  2. 参数acks， 这个参数是用户自己设置的，告诉 kafka 需要保证的消息的严谨程度
  3. 参数retry， 这个也是用户自己设置的，告诉kafka 需要重试多少次
  4.retry.backoff.m 这个也是用户自己设置的，超时时间。
  
  上面 2 ~ 3 都是为了保证消息不丢失，但是用户实际用到的就是第一种，自己关系这个消息到底有没有丢失。
  
  
  broker 上保证消息不丢失
  replication factor
  表示分区副本的个数，replication.factor >1 当leader 副本挂了，follower副本会被选举为leader继续提供服务。
  
  min.insync.replicas
  表示 ISR 最少的副本数量，通常设置 min.insync.replicas >1，这样才有可用的follower副本执行替换，保证消息不丢失
  
  unclean.leader.election.enable
  是否可以把非 ISR 集合中的副本选举为 leader 副本。
  如果设置为true，而follower副本的同步消息进度落后较多，此时被选举为leader，会导致消息丢失，慎用。
  
  isr 是一类没有落后太多副本的名称
  
  
  concumser 怎么保证消息不丢失
  提交位移，但是位移的提交难免有问题，会出现重复消费的问题，我们可以通过代码的幂等性保证。
  ```

* Kafka, rabbimtmq, rocketmq 的区别

  ```
  1.场景：kafka 更适合日志处理， rocketmq 适合业务处理 ，rabbitmq 的消息严谨性更高
  
  
  2.性能 kafka 单机性能 百万条/s, rocketmq 10w/s
  
  3.支持的单机数，Kafka单机超过64个队列/分区，消息发送性能降低严重  RocketMQ 单机支持最高5万个队列，性能稳定
  
  4.消费失败重试机制 （kafka, 一般都是手动提交offset， 然后放到重试 topic， 或者死信队列，),rabbitmq 可以 nack， 消息会重新放到队列中。之所以这样是因为 rabbitmq 消息确认后就会删除，kafka 永久存储（可以根据时间，大小来删除）。kafka 只有生产者才有 ack 机制。如果说到 保证消息不丢失，我们要从生产者（ack） --》broker （副本，镜像） --》 消费者 （ack， offset） 来说保证消息不丢失。
  
  5. kafka 是拉消息，所有消息都存储了，利用offset 去控制消息进度。但是rabbitmq 是 推消息，消息消费完就删除了。还有rabbitmq 需要手动建立队列去接受数据，比如某个时刻队列还没有建立，那这个消息就丢失了。
   
   
  6.kafka 不支持定时消息，rocketmq 支持。 kafka 顺序发送，第一条消息sleep 一段时间，后面消息就不用sleep 了。 rocketmq 支持， rabbitmq 可以通过 死信队列做延迟队列的功能
  
  7.消息查询。
  kafka 不支持消息查询 。我们平时都是通过消费出来，记录日志， 查询kafka 消息。
  rabbitmq ，确认值后直接删除了消息，所以不存在消息查询，只是能批量取 （rabbitmq 消息持久化是把未发送的消息持久化）
  rocketmq 支持messag id 查询。
  
  8.消息回溯。
  kafka 可以按照offset，
  rocketmq 可以按照时间。真厉害。
  rabbitmq 发送的消息删除了，所以没有回溯功能
  
  9.延迟队列，rabbitmq 和 rocketmq 支持，kafka 不支持。
  
  10.rabbitmq 怕堆积，是因为数据存储在了内存中，操作都是通过内存。kafka 是通过顺序读写磁盘日志。
  
  11. rabbitmq 不支持批量发送 （推送机制）
  ```

* rabbitmq 积压导致内存爆掉，kafka 为什么不会

  ```
  rabbitmq 内存型 （如果开启了持久化，也会写入磁盘），而且是推的模式，不能根据消费方调节推送频率。
  
  kafka 消费的数据是在磁盘文件，通过动态调整offset来调整消费位置
  ```

  

* rabbitmq 的消息确认机制，项目里面怎么确认的

  ```
  生产者：
  
  事务，可以方便多条消息的确认，发送效率低。
  confirm， 效率高。有单条confirm， 多条，还有异步监听。
  
  消费者:
  ack 和 nack 对消息进行应答
  ```

* Redis 消息队列保证可靠性

  ```
  redis list  brpop 阻塞式拉取。 防止cpu 空转  （拉消息）
  
  redis 发布订阅。 解决了消息可以被多个消费类型消费者消费。（推消息，所以消费者下线，消息就丢失了， rabbitmq 也会遇到这个问题）
  
  redis stream ，阻塞式拉取， 多消费类型消费。应答模式，防止消息丢失 （就没有消息的存储）
  
  （想一下 rabbitmq 的应答模式，收到ack 再删除消息，如果是同一条消息被多个类型消费者消费呢？有的还没消费怎么办。 因为我们的所有消息都需要 queue 去接受，所以同一条消息会有在不同消费者队列中存在，所以不存在你ack 了别人消息的情况）
  
  https://www.zhihu.com/question/43688764
  ```

  



* 消息写入策略

  ```
  kafka  
  hash message_key
  
  轮训，
  
  随机
  
  ```

* rabbitmq 连接维持

  ```
  https://www.dazhuanlan.com/supershuai1027/topics/1151025
  
  心跳机制
  
  断线重连
  ```

  

* Kafka 10个分区，一个消费者 ，golang 会启几个协程

  ```
  感觉这和golang 没什么关系。这个消费者可以消费到所有分区的消息。一个消费者如果指的是一个pod，我们可以启动 多个协程比如10个组成消费者组去消费（当然可以更少），保证消息最大限度上的路由机制。 也可以用单消费者模式。
  ```

* kafka 的offset 存在哪里

  ```
  以前写在zookeeper 中，但发现zookeeper 不适合频繁读写，现在写在了特定的topic 中，内存中也维护了一份 consumer group， topic， offset 的 三元组
  
  因为这部分消息是非常重要，以至于是不能容忍丢数据的，所以消息的 acking 级别设置为了 -1，
  ```

* kakfa 的几个概念

  ```
  https://www.cnblogs.com/doit8791/p/11306844.html
  
  Last Committed Offset：consumer group 最新一次 commit 的 offset，表示这个 group 已经把 Last Committed Offset 之前的数据都消费成功了。
  
  
  Current Position：consumer group 当前消费数据的 offset，也就是说，Last Committed Offset 到 Current Position 之间的数据已经拉取成功，可能正在处理，但是还未 commit。 （kafka 是主动拉消息，拉消息的条数也是有限制的）
  
  Log End Offset(LEO)：记录底层日志 (log) 中的下一条消息的 offset。, 对 producer 来说，就是即将插入下一条消息的 offset。（生产者有关）
  
  High Watermark(HW)：已经成功备份到其他 replicas 中的最新一条数据的 offset，也就是说 Log End Offset 与 High Watermark 之间的数据已经写入到该 partition 的 leader 中，但是还未完全备份到其他的 replicas 中，consumer 是无法消费这部分消息 (未提交消息，消息备份，所以如果leader 死了，然后消息没有同步到副本中， 然后ack 是 0 级别，就容易丢消息)。
  
  感觉这个leader 副本就是数据主体的感觉
  ```



* kafka如何保证消息都发到指定分区上

  ```
  1. msg key hash 模式， msg 的key 给定值
  2. 单分区
  ```

* kafka 的producer 幂等性

  ```
  kafka 的 producer 虽然 自身能保证幂等性 （只能是kafka 的发送重试 等机制的幂等性保证，去重消息）， 但是无法保证 生产者对于重复消息的发送，所以为了保证结果的幂等性，最终还是 consumer 代码中要保证幂等性。
  ```

  

  

* kafka 为什么快

  ````
  1.利用了磁盘连续读写性能远远高于随机读写的特点。
  
  2.内部采用消息的批量处理 
  
  3.zero-copy 
  https://www.jianshu.com/p/0af1b4f1e164
  
  传统： 磁盘-》 内核 buffer -》 应用层 buffer -> 内核 socket buffer -》消费者
  kakfa: 磁盘 -》 内核buffer -》 内核 socket buffer -》 消费者
  
  
  4.并发，将一个 topic 拆分多个 partition， kafka 读写的单位是 partition，因此，将一个 topic 拆分为多个 partition 可以提高吞吐量。但是，这里有个前提，就是不同 partition 需要位于不同的磁盘（可以在同一个机器）。如果多个 partition 位于同一个磁盘，那么意味着有多个进程同时对一个磁盘的多个文件进行读写，使得操作系统会对磁盘读写进行频繁调度，也就是破坏了磁盘读写的连续性。
  在 linkedlin 的测试中，每台机器就加载了 6 个磁盘，并且不做 raid，就是为了充分利用多磁盘并发读写，又保证每个磁盘连续读写的特性。
  ````

  

* 限流，熔断，降级 (怎么实现)

  ```
  1.限流 （令牌桶，滑动窗口，漏斗桶 uber开源的那套）
  2.熔断  （hystrix-go）
  3.降级 
  ```

* 服务治理是什么

  ```
  1、限流
  2. 熔断 （获取一段时间内，失败的请求 占用所有请求百分比，达到某个阈值，开启部分流量的直接返回。实时监控，如果某段时间内，错误占比低于阈值，再关闭对应流量）
  3.降级 （配合熔断来，一般有的依赖方熔断分流的不直接返回错误，而是降级。有的依赖方没有做，我们自己做降级）
  4. 负载均衡 （轮训，随机，hash，权重，）
  ```

* 架构图

  ```
  slb -> kong(openresty, nginx) -> consul ->后端
  ```

* kafka 的key 怎么分配到分区的

  ```
  key -->hash  % partition 取模，投递到具体的consumer 中。（源码没有具体研究过，就是想投递到同一个partition 上的消息，用同一个key）
  ```

* p 和 consumer 的分配

  ```
  partition 的数量 >= consumer 的数量
  
  一个 p 只能投递到固定的一个 consumer 中。 多个p 也可以投递到一个 consumer 中
  
  ```
  
  
  
  
