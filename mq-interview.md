* 为什么有些人称kafka ， rabbitmq 这些为 mq框架 

  ```
  我们刚开始写代码的时候会把 tp， laravel，gin 这些称作框架，理解的意思就是用某种语言封装了一些通用方法，搭建了项目骨架 Skelton，帮助我们更快更方便的写代码。我们写的项目基本上都是以一个框架为主题，然后扩展其中的某个文件夹。这种想法会在我们心中有个先入为主的概念，不能理解一款mq 为什么可以称之为消息框架，难道有人用kafka 做项目 ？
  其实我们做项目的时候，tp， laravel gin 这些更类似于组件 components，他们是项目的附属品而不是主体， 我们的 项目中可以既 集成了 tp ，也集成laravel （因为二者有对相同功能的封装，这样做很浪费，所以一般不会这么做），那是不是 kafka 我们也可以称之为组件。是这样的，但我们代码中一般集成的我们代码语言编写的 客户端sdk ，他和 kafka 这些软件本质上没有多少关系，其实就是为了连接他们，发送请求，符合kafka 的协议写的一种 收发器。（kafka， redis， mysql 其实本质上都是一样的， 他们都属于一种中间件，一种 语言写的软件，我们平时的代码中集成的是 一些人为其写的接入 客户端，比如如何建立tcp 连接，如何 收发消息）。
  ```

* mq 的使用场景

  ```
  1.削峰填谷。缓冲上下游瞬时突发流量，保护“脆弱”的下游系统不被压垮，避免引发全链路服务“雪崩”。（口碑项目保护算法提取关键词，返现项目主要是外部公司暴露出去的一般用的都是api 项目，比如我们要获取订单，都是通过一个地方 job 拉订单，然后放到消息队列中，让各个业务方自行订阅消费）
  2.系统解耦。发送方和接收方的松耦合，一定程度简化了开发成本，减少了系统间不必要的直接依赖。(微服务)发布订阅模式。 （依赖方的重构，域名 or 路由名  or http -> rpc 的改变，相比较 msg 结果可能更加不会改变）
  3.异步处理。（解决超时问题）
  ```

* mq 的消息顺序问题，如何解决

  ```
  保证局部有序，mq 组件会自己先保证能提供大部分场景下数据的一致性。比如kafka 我们在发送消息的时候实则 msg 的key， 让其消息在正常情况下都路由到同一个partition 上。（路由规则的场景使用很多，比如负载均衡，常用的有hash， random， 顺序，权重）。
  
  但mq 并不能强保证，比如 扩容 或者发版导致消费者变更 进一步导致 kafka reblance 的时候。我们可以通过首先添加分布式锁保证某类消息没有并发问题，解决reblance 的消息重复问题。再根据我们 记录变动的时候存储的 消息时间，保证 先产生的消息一定不会在 后产生的消息之前执行，如果存在，直接丢弃，记录异常。
  
  感觉我们的消息重复问题应该是平滑重启导致。 程序监听到 信号，重新启动一个新的进程处理脚本任务，老的脚本停止停止流量进入，关闭。但是这个中间时间可能有老的消费者和新的消费者都存在（offset后置提交），所以导致了消息重复消费。
  ```

* 如何保证一个队列只有一个消费端

  ```
  kafka 的队列也就是 routeing key 可以对应多个分区，多个分区对应多个消费者，但单个分区只能对应多个消费者，但是reblance 的时候会存在异常，对应多个（是那种多个消费者可以消费同条消息多次的那种），分布式锁登场。
  
  感觉多个消费者无法保证offset 的顺序性。
  ```

* 如果扩容了怎么办

  ```
  我们的代码中如果保证了消息的幂等性，顺序性，扩容导致的异常情况都不用考虑了
  ```

* 顺序消息，如果某条失败了怎么办？ 会不会一直阻塞

  ```
  1、如果失败，不会提交消费位移，系统会自动重试（有重试上限），此时会阻塞后面的消息消费，直到这条消息处理完。
  
  2、如果这个消息达到重试上限，依然失败，会进入死信队列（题外话 我们的rabbitmq 死信队列当做延迟队列，）， ，可以继续处理后面的消息
  
  rabbitmq:
  
  kafka: https://cloud.tencent.com/developer/article/1698552。 kafka 是怎么
  发送消息的： 现在的kafka 应该都是异步发送，先写到缓冲池里面，在通过一个特殊线程去拉数据发送，然后把发送结果 回调回来。如果发送线程太慢，导致缓冲区内存耗尽，就会出现发送阻塞。又或者第一次发送数据，需要 这个线程去获取 topic 的元信息，给到producer， producer 拿着元信息 metadata， 拼接在 要发送的每条消息上， 这个过程也可能出现消息堵塞
  
  以前是有：
  1. 发送并忘记。
  
  2. 同步发送 。
  
  3. 异步发送 + 回调函数。
  
  3 种方式虽然在时间上有所差别，但并不是说时间越快的越好，具体使用哪种方式要看具体的业务场景，比如业务要求消息必须是按顺序发送，可以使用第 2 种同步发送，并且只能在一个 partation 上。如果业务只关心消息的吞吐量，容许少量消息发送失败，也不关注消息的发送顺序，那么可以使用发送并忘记的方式。如果业务需要知道消息发送是否成功，并且对消息的顺序不关心，那么可以用异步 + 回调的方式来发送消息
  
  ```



* kafka 中的名词

  ```
  Broker：接收客户端发送过来的消息，对消息进行持久化
  主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。(队列的一种意识形态，我这么认为 哈哈哈)
  分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。
  消息：这里的消息就是指 Kafka 处理的主要对象。
  消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。
  副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。每个分区可配置多个副本实现高可用。一个分区的N个副本一定在N个不同的Broker上。
  生产者：Producer。向主题发布新消息的应用程序。
  消费者：Consumer。从主题订阅新消息的应用程序。
  消费者位移：Consumer Offset。表示消费者消费进度，每个消费者都有自己的消费者位移。offset保存在broker端的内部topic中，不是在clients中保存 （如果保存在client 端，client 挂掉了，或者重新发布了，offset 就消失了）
  消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。
  重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区
  ```

  

* zookeeper 在里面的职责

  ```
  它是一个分布式协调框架，负责协调管理并保存 Kafka 集群的所有元数据信息，比如集群都有哪些 Broker 在运行、创建了哪些 Topic，每个 Topic 都有多少分区以及这些分区的 Leader 副本都在哪些机器上等信息。
  
  查询下zookeeper 的api。zookeeper 的使用场景
  ```

* 消息传输的格式

  ```
  纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列
  
  http 协议， redis 协议 ，kafka 的消息协议，应该都是属于应用层的协议， 我们 的 客户端sdk 中要处理的这些协议包。对于 tcp 层粘包 拆包 属于 tcp 层，我们应该处理的比较少。
  ```

  

* 消息模式

  ```
  点对点模型。系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息 (这种最简单)
  发布/订阅模型。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。
  
  我一般自己刷数据，数据量少，用的就是点对点模式。
  
  发布订阅工作用的比较多，主要一种消息可能会被多家订阅
  ```

* 消息压缩

  ```
  生产者程序中配置compression.type 参数即表示启用指定类型的压缩算法。
  
  props.put(“compression.type”, “gzip”)，它表明该 Producer 的压缩算法使用的是GZIP。这样 Producer 启动后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好地节省网络传输带宽以及 Kafka Broker 端的磁盘占用。
  
  但如果Broker又指定了不同的压缩算法，如：Snappy，会将生产端的消息解压然后按自己的算法重新压缩。
  
  各压缩算法比较：吞吐量方面：LZ4 > Snappy > zstd 和 GZIP；而在压缩比方面，zstd > LZ4 > GZIP > Snappy。
  
  kafka默认不指定压缩算法。
  ```

* 消息解压缩

  ```
  当 Consumer pull消息时，Broker 会原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原成之前的消息。
  ```

* 生产者管理tcp 连接

  ```
  在new KafkaProducer 实例时，生产者应用会在后台创建并启动一个名为 Sender 的线程，该 Sender 线程开始运行时首先会创建与 Broker 的连接。此时还不知道给哪个topic发消息，所以Producer 启动时会发起与所有的 Broker 的连接。
  
  Producer 通过metadata.max.age.ms 参数定期地去更新元数据信息，默认值是 300000，即 5 分钟，不管集群那边是否有变化，Producer 每 5 分钟都会强制刷新一次元数据以保证它是最新的数据
  
  （拉取的原数据是什么）
  ```

  

* producer 发送消息

  ```
  Producer 使用带回调通知的发送 API， producer.send(msg, callback)。
  
  设置 acks = all。Producer 的一个参数，表示所有副本都成功接收到消息，该消息才算是“已提交”，最高等级，acks的其它值说明。min.insync.replicas > 1，表示消息至少要被写入到多少个副本才算是“已提交”
  
  retries 是 Producer 的参数。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 Producer 能够自动重试消息发送，避免消息丢失。
  
  之前用rabbitmq 发送消息，异步发送是等到 缓冲区满了，一次性 flush，所以是异步接受
  ```

* 幂等性 producer (虽然可以用， 但我们不使用，因为我们代码中可以做这些事，kafka 提供的这些功能可以帮助我们过滤掉一部分数据)

  ```
  设置参数props.put(“enable.idempotence”, ture)，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变。Kafka 自动帮你做消息的重复去重。
  
  原理很简单，就是经典的空间换时间，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，可以在后台默默地把它们“丢弃”掉。
  
  只能保证单分区、单会话上的消息幂等性。一个幂等性 Producer 能够保证某个topic的一个分区上不出现重复消息，但无法实现多个分区的幂等性。比如采用轮询，下一次提交换了一个分区就无法解决
  ```

* 事务性producer

  ```
  能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。能够保证跨分区、跨会话间的幂等性。
  
  实际上即使写入失败，Kafka 也会把它们写入到底层的日志中，也就是说 Consumer 还是会看到这些消息。要不要处理在 Consumer 端设置 isolation.level ，这个参数有两个值:
  
  read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息
  read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息
  ```

* kafka broker 是如何存储数据的

  ```
  Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。
  
  不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？
  
  简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。
  ```

* kafka 的备份机制

  ```
  相同的数据拷贝到多台机器上。副本的数量是可以配置的。Kafka 中follow副本不会对外提供服务。
  
  副本的工作机制也很简单：生产者总是向leader副本写消息；而消费者总是从leader副本读消息。至于follow副本，它只做一件事：向leader副本以异步方式发送pull请求，请求leader把最新的消息同步给它，必然有一个时间窗口导致它和leader中的数据是不一致的，或者说它是落后于leader。
  
  那我们消费的是副本 ？
  
  
  ```

* 为什么要引入消费者组

  ```
  主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。
  
  在一个消费者组下，一个分区只能被一个消费者消费，但一个消费者可能被分配多个分区，因而在提交位移时也就能提交多个分区的位移。如果1个topic有2个分区，消费者组有3个消费者，有一个消费者将无法分配到任何分区，处于idle状态。
  
  理想情况下，Consumer 实例的数量应该等于该 Group 订阅topic（可能多个）的分区总数。
  ```

* 消费端offset 管理

  ```
  1）老版本的 Consumer组把位移保存在 ZooKeeper 中，但很快发现zk并不适合频繁的写更新。
  
  2）在新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer组的位移管理方式，采用了将位移保存在 Broker端的内部topic中，也称为“位移主题”，由kafka自己来管理。原理很简单， Consumer的位移数据作为一条条普通的 Kafka 消息，提交到__consumer_offsets 中。它的消息格式由 Kafka 自己定义，用户不能修改。位移主题的 Key 主要包括 3 部分内容：<Group ID，topic名，分区号 >
  
  topIC 分区号 用来区分 哪个topic， group id 用来区分 group
  
  Kafka Consumer 提交位移的方式有两种：自动提交位移和手动提交位移。
  
  Kafka 使用Compact策略来删除位移主题中的过期消息，避免该topic无限期膨胀。提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。
  ```

  

* rebalance 的触发条件

  ```
  1）组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，又或是有 Consumer 实例崩溃被“踢出”组。（99%原因是由它导致）
  
  2） 订阅topic数发生变更。Consumer Group 可以使用正则表达式的方式订阅topic，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的topic。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的topic，那么该 Group 就会发生 Rebalance。 (第二种用的少，因为我们自己的业务都是 自己生产，自己消费)
  
  3） 订阅topic的分区数发生变化。Kafka 目前只允许增加topic的分区数。当分区数增加时，也会触发订阅该topic的所有 Group 开启 Rebalance。
  ```

  

* 消费的顺序性

  ```
  Kafka的设计中多个分区的话无法保证全局的消息顺序。如果一定要实现全局的消息顺序，只能单分区。
  
  方法二：通过有key分组，同一个key的消息放入同一个分区，保证局部有序
  ```

  

* 历史数据清理 (有些问题虽然可能没遇见过，但可以自己想)

  ```
  基于保存时间，log.retention.hours
  基于日志大小的清理策略。通过log.retention.bytes控制
  组合方式
  ```

  

* kafka 效率高的原因

  ```
  1. 顺序读写。
  2.零copy 技术
  ```

* kafka 怎么保证消息不丢失

  ```
  发送的是否 保证消息不丢失
  1. 生产者 callback， 这个是告诉用户消息有没有丢失
  2. 参数acks， 这个参数是用户自己设置的，告诉 kafka 需要保证的消息的严谨程度
  3. 参数retry， 这个也是用户自己设置的，告诉kafka 需要重试多少次
  4.retry.backoff.m 这个也是用户自己设置的，超时时间。
  
  上面 2 ~ 3 都是为了保证消息不丢失，但是用户实际用到的就是第一种，自己关系这个消息到底有没有丢失。
  
  
  broker 上保证消息不丢失
  replication factor
  表示分区副本的个数，replication.factor >1 当leader 副本挂了，follower副本会被选举为leader继续提供服务。
  
  min.insync.replicas
  表示 ISR 最少的副本数量，通常设置 min.insync.replicas >1，这样才有可用的follower副本执行替换，保证消息不丢失
  
  unclean.leader.election.enable
  是否可以把非 ISR 集合中的副本选举为 leader 副本。
  如果设置为true，而follower副本的同步消息进度落后较多，此时被选举为leader，会导致消息丢失，慎用。
  
  isr 是一类没有落后太多副本的名称
  
  
  concumser 怎么保证消息不丢失
  提交位移，但是位移的提交难免有问题，会出现重复消费的问题，我们可以通过代码的幂等性保证。
  ```

* Kafka, rabbimtmq, rocketmq 的区别

  ```
  1.场景：kafka 更适合日志处理， rocketmq 适合业务处理 ，rabbitmq 的消息严谨性更高
  
  
  2.性能 kafka 单机性能 百万条/s, rocketmq 10w/s
  
  3.支持的单机数，Kafka单机超过64个队列/分区，消息发送性能降低严重  RocketMQ 单机支持最高5万个队列，性能稳定
  
  4.消费失败重试机制 （kafka, 一般都是手动提交offset， 然后放到重试 topic， 或者死信队列，),rabbitmq 可以 nack， 消息会重新放到队列中。之所以这样是因为 rabbitmq 消息确认后就会删除，kafka 永久存储（可以根据时间，大小来删除）。kafka 只有生产者才有 ack 机制。如果说到 保证消息不丢失，我们要从生产者（ack） --》broker （副本，镜像） --》 消费者 （ack， offset） 来说保证消息不丢失。
  
  5. kafka 是拉消息，所有消息都存储了，利用offset 去控制消息进度。但是rabbitmq 是 推消息，比如某个时刻队列还没有建立，那这个消息就丢失了。
   
   
  6.kafka 不支持定时消息，rocketmq 支持。 kafka 顺序发送，第一条消息sleep 一段时间，后面消息就不用sleep 了。 rocketmq 支持， rabbitmq 可以通过 死信队列做延迟队列的功能
  
  7.消息查询。
  kafka 不支持消息查询 。我们平时都是通过消费出来，记录日志， 查询kafka 消息。
  rabbitmq ，确认值后直接删除了消息，所以不存在消息查询，只是能批量取 （rabbitmq 消息持久化是把未发送的消息持久化）
  rocketmq 支持messag id 查询。
  
  8.消息回溯。
  kafka 可以按照offset，
  rocketmq 可以按照时间。真厉害。
  rabbitmq 发送的消息删除了，所以没有回溯功能
  
  9.延迟队列，rabbitmq 和 rocketmq 支持，kafka 不支持。
  
  10.rabbitmq 怕堆积，是因为数据存储在了内存中，操作都是通过内存。kafka 是通过顺序读写磁盘日志。
  
  11. rabbitmq 不支持批量发送
  ```

* rabbitmq 积压导致内存爆掉，kafka 为什么不会

  ```
  当RabbitMQ收到消息时，如果是持久化消息，则会储存在内存中，同时也会写入磁盘；如果是非持久化消息，则只会存在内存中
  ```

  

* rabbitmq 的消息确认机制，项目里面怎么确认的

  ```
  生产者：
  
  事务，可以方便多条消息的确认，发送效率低。
  confirm， 效率高。有单条confirm， 多条，还有异步监听。
  
  消费者:
  ack 和 nack 对消息进行应答
  ```

* Redis 消息队列保证可靠性

  ```
  redis list  brpop 阻塞式拉取。 防止cpu 空转  （拉消息）
  
  redis 发布订阅。 解决了消息可以被多个消费类型消费者消费。（推消息，所以消费者下线，消息就丢失了）
  
  redis stream ，阻塞式拉取， 多消费类型消费。应答模式，防止消息丢失
  
  （想一下 rabbitmq 的应答模式，收到ack 再删除消息，如果是同一条消息被多个类型消费者消费呢？有的还没消费怎么办。 因为我们的所有消息都需要 queue 去接受，所以同一条消息会有在不同消费者队列中存在，所以不存在你ack 了别人消息的情况）
  
  https://www.zhihu.com/question/43688764
  ```

  



* 消息分发策略

  ```
  kafka  
  hash message_key
  轮训，随机策略 
  
  rabbitmq
  轮训，随机策略
  ```

* rabbitmq 连接维持

  ```
  https://www.dazhuanlan.com/supershuai1027/topics/1151025
  
  心跳机制
  
  断线重连
  ```

  

* Kafka 10个分区，一个消费者 ，golang 会启几个协程

  ```
  感觉这和golang 没什么关系。这个消费者可以消费到所有分区的消息。一个消费者如果指的是一个pod，我们可以启动 多个协程比如10个组成消费者组去消费（当然可以更少），保证消息最大限度上的路由机制。 也可以用单消费者模式。
  ```

* kafka 的offset 存在哪里

  ```
  以前写在zookeeper 中，但发现zookeeper 不适合频繁读写，现在写在了特定的topic 中，内存中也维护了一份 consumer group， topic， offset 的 三元组
  
  因为这部分消息是非常重要，以至于是不能容忍丢数据的，所以消息的 acking 级别设置为了 -1，
  ```

* kakfa 的几个概念

  ```
  https://www.cnblogs.com/doit8791/p/11306844.html
  
  Last Committed Offset：consumer group 最新一次 commit 的 offset，表示这个 group 已经把 Last Committed Offset 之前的数据都消费成功了。
  
  
  Current Position：consumer group 当前消费数据的 offset，也就是说，Last Committed Offset 到 Current Position 之间的数据已经拉取成功，可能正在处理，但是还未 commit。 （kafka 是主动拉消息，拉消息的条数也是有限制的）
  
  Log End Offset(LEO)：记录底层日志 (log) 中的下一条消息的 offset。, 对 producer 来说，就是即将插入下一条消息的 offset。（生产者有关）
  
  High Watermark(HW)：已经成功备份到其他 replicas 中的最新一条数据的 offset，也就是说 Log End Offset 与 High Watermark 之间的数据已经写入到该 partition 的 leader 中，但是还未完全备份到其他的 replicas 中，consumer 是无法消费这部分消息 (未提交消息，消息备份，所以如果leader 死了，然后消息没有同步到副本中， 然后ack 是 0 级别，就容易丢消息)。
  ```



* kafka如何保证消息都发到指定分区上

  ```
  1. msg key hash 模式， msg 的key 给定值
  2. 单分区
  ```

* kafka 的producer 幂等性

  ```
  kafka 的 producer 虽然 自身能保证幂等性 （只能是kafka 的发送重试 等机制的幂等性保证，去重消息）， 但是无法保证 生产者对于重复消息的发送，所以为了保证结果的幂等性，最终还是 consumer 代码中要保证幂等性。
  ```

* 幂等性怎么保证

  ```
  1.新增类型，生成唯一id保证。
  2.更新类型，根据更新时间
  4.对消息进行记录，消费过的打上标志位
  （为了防止并发，要加上分布式锁）
  ```

  

* kafka 为什么快

  ````
  1.利用了磁盘连续读写性能远远高于随机读写的特点，内部采用消息的批量处理，zero-copy 机制，数据的存储和获取是本地磁盘顺序批量操作，具有 O (1) 的复杂度，消息处理的效率很高。
  
  2.并发，将一个 topic 拆分多个 partition， kafka 读写的单位是 partition，因此，将一个 topic 拆分为多个 partition 可以提高吞吐量。但是，这里有个前提，就是不同 partition 需要位于不同的磁盘（可以在同一个机器）。如果多个 partition 位于同一个磁盘，那么意味着有多个进程同时对一个磁盘的多个文件进行读写，使得操作系统会对磁盘读写进行频繁调度，也就是破坏了磁盘读写的连续性。
  在 linkedlin 的测试中，每台机器就加载了 6 个磁盘，并且不做 raid，就是为了充分利用多磁盘并发读写，又保证每个磁盘连续读写的特性。
  ````

* 幂等性怎么保证 （重复消费的问题）

  ```
  1.对接受的消息持久化存储，消费消息前对比
  2.消息添加时间（比如状态变更时间）
  ```

* 顺序消费为题

  ```
  1.添加时间
  2.单消费者，单生产者
  3.添加message key
  ```

* 限流，熔断，降级 (怎么实现)

  ```
  ```

* 服务治理是什么

  ```
  ```

* 架构图

  ```
  ```

* kafka 的key 怎么分配到分区的

  ```
  key -->hash  % partition 取模，投递到具体的consumer 中
  ```

* p 和 consumer 的分配

  ```
  p 的数量 >= consumer 的数量
  
  一个 p 只能投递到固定的一个 consumer 中。 多个p 也可以投递到一个 consumer 中
  
  （难道是不想多建立链接 ？还是保证顺序）
  ```

  
